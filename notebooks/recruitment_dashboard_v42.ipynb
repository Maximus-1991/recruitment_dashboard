{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "#How to safely pass in PW (where to store it?)\n",
    "#Check if can find source in API\n",
    "#Create functions\n",
    "#Create docker image\n",
    "#Host image in cloud\n",
    "#Flask webapp\n",
    "\n",
    "#CHange default values in functions to Google Cloud SQL DB\n",
    "\n",
    "# Check why max_id doesnt work\n",
    "\n",
    "# Write .py functions\n",
    "# Dockers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maarten\\Anaconda3\\envs\\ams\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import dateutil.relativedelta\n",
    "import pytz\n",
    "import random\n",
    "from datetime import date\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "#import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Sequence\n",
    "from itertools import chain, count, tee\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'key1':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a,dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(user='root', password='maartens1991', host='127.0.0.1', port = '3306', database='recruitment_dashboard', auth_plugin='mysql_native_password')\n",
    "bc = pd.read_sql(\"SELECT * from candidates2\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>headline</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>shortcode</th>\n",
       "      <th>title</th>\n",
       "      <th>stage</th>\n",
       "      <th>disqualified</th>\n",
       "      <th>...</th>\n",
       "      <th>Applied</th>\n",
       "      <th>Shortlisted</th>\n",
       "      <th>Talentpool</th>\n",
       "      <th>Review</th>\n",
       "      <th>To schedule</th>\n",
       "      <th>1st Interview</th>\n",
       "      <th>2nd Interview</th>\n",
       "      <th>Offer</th>\n",
       "      <th>Hired</th>\n",
       "      <th>disqualified_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ddb204</td>\n",
       "      <td>niels drost</td>\n",
       "      <td>niels</td>\n",
       "      <td>drost</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>a8c5321f60</td>\n",
       "      <td>big data scientist (bdr)</td>\n",
       "      <td>1st interview</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ddb571</td>\n",
       "      <td>paula l amaral santos</td>\n",
       "      <td>paula l</td>\n",
       "      <td>amaral santos</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>a8c5321f60</td>\n",
       "      <td>big data scientist (bdr)</td>\n",
       "      <td>hired</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ddb572</td>\n",
       "      <td>gulliver de boer</td>\n",
       "      <td>gulliver</td>\n",
       "      <td>de boer</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>a8c5321f60</td>\n",
       "      <td>big data scientist (bdr)</td>\n",
       "      <td>2nd interview</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ddb582</td>\n",
       "      <td>pieter kouyzer</td>\n",
       "      <td>pieter</td>\n",
       "      <td>kouyzer</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>a8c5321f60</td>\n",
       "      <td>big data scientist (bdr)</td>\n",
       "      <td>talentpool</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ddb9ca</td>\n",
       "      <td>profiel van aris koning</td>\n",
       "      <td>profiel van aris</td>\n",
       "      <td>koning</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>a8c5321f60</td>\n",
       "      <td>big data scientist (bdr)</td>\n",
       "      <td>2nd interview</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5192</td>\n",
       "      <td>48ea0c4</td>\n",
       "      <td>babak loni</td>\n",
       "      <td>babak</td>\n",
       "      <td>loni</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>5e4dc1408a</td>\n",
       "      <td>data scientist (vantage ai)</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5193</td>\n",
       "      <td>48ea1c3</td>\n",
       "      <td>adam vandor</td>\n",
       "      <td>adam</td>\n",
       "      <td>vandor</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>5e4dc1408a</td>\n",
       "      <td>data scientist (vantage ai)</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5194</td>\n",
       "      <td>48ea22f</td>\n",
       "      <td>simona elena necula</td>\n",
       "      <td>simona</td>\n",
       "      <td>elena necula</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>a8c5321f60</td>\n",
       "      <td>big data scientist (bdr)</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5195</td>\n",
       "      <td>48ea3e5</td>\n",
       "      <td>praan doelam</td>\n",
       "      <td>praan</td>\n",
       "      <td>doelam</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>9882e4c0ea</td>\n",
       "      <td>java developer (jdriven)</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5196</td>\n",
       "      <td>48eb0ae</td>\n",
       "      <td>julitte veldhuis</td>\n",
       "      <td>julitte</td>\n",
       "      <td>veldhuis</td>\n",
       "      <td>None</td>\n",
       "      <td>jdriven</td>\n",
       "      <td>73ed57abba</td>\n",
       "      <td>accountmanager</td>\n",
       "      <td>1st interview</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                     name         firstname       lastname  \\\n",
       "0      ddb204              niels drost             niels          drost   \n",
       "1      ddb571    paula l amaral santos           paula l  amaral santos   \n",
       "2      ddb572         gulliver de boer          gulliver        de boer   \n",
       "3      ddb582           pieter kouyzer            pieter        kouyzer   \n",
       "4      ddb9ca  profiel van aris koning  profiel van aris         koning   \n",
       "...       ...                      ...               ...            ...   \n",
       "5192  48ea0c4               babak loni             babak           loni   \n",
       "5193  48ea1c3              adam vandor              adam         vandor   \n",
       "5194  48ea22f      simona elena necula            simona   elena necula   \n",
       "5195  48ea3e5             praan doelam             praan         doelam   \n",
       "5196  48eb0ae         julitte veldhuis           julitte       veldhuis   \n",
       "\n",
       "     headline subdomain   shortcode                        title  \\\n",
       "0        None   jdriven  a8c5321f60     big data scientist (bdr)   \n",
       "1        None   jdriven  a8c5321f60     big data scientist (bdr)   \n",
       "2        None   jdriven  a8c5321f60     big data scientist (bdr)   \n",
       "3        None   jdriven  a8c5321f60     big data scientist (bdr)   \n",
       "4        None   jdriven  a8c5321f60     big data scientist (bdr)   \n",
       "...       ...       ...         ...                          ...   \n",
       "5192     None   jdriven  5e4dc1408a  data scientist (vantage ai)   \n",
       "5193     None   jdriven  5e4dc1408a  data scientist (vantage ai)   \n",
       "5194     None   jdriven  a8c5321f60     big data scientist (bdr)   \n",
       "5195     None   jdriven  9882e4c0ea     java developer (jdriven)   \n",
       "5196     None   jdriven  73ed57abba               accountmanager   \n",
       "\n",
       "              stage  disqualified  ... Applied Shortlisted  Talentpool Review  \\\n",
       "0     1st interview             1  ...     NaT         NaT         NaT    NaT   \n",
       "1             hired             0  ...     NaT         NaT         NaT    NaT   \n",
       "2     2nd interview             1  ...     NaT         NaT         NaT    NaT   \n",
       "3        talentpool             0  ...     NaT         NaT  2019-02-01    NaT   \n",
       "4     2nd interview             1  ...     NaT         NaT         NaT    NaT   \n",
       "...             ...           ...  ...     ...         ...         ...    ...   \n",
       "5192         review             0  ...     NaT         NaT         NaT    NaT   \n",
       "5193         review             0  ...     NaT         NaT         NaT    NaT   \n",
       "5194         review             0  ...     NaT         NaT         NaT    NaT   \n",
       "5195         review             0  ...     NaT         NaT         NaT    NaT   \n",
       "5196  1st interview             0  ...     NaT         NaT         NaT    NaT   \n",
       "\n",
       "     To schedule 1st Interview 2nd Interview      Offer      Hired  \\\n",
       "0            NaT    2019-01-08           NaT        NaT        NaT   \n",
       "1            NaT    2016-09-05    2016-09-26 2016-10-07 2016-10-14   \n",
       "2            NaT    2016-09-05    2016-09-20        NaT        NaT   \n",
       "3            NaT    2016-09-05           NaT        NaT        NaT   \n",
       "4            NaT           NaT    2016-09-05        NaT        NaT   \n",
       "...          ...           ...           ...        ...        ...   \n",
       "5192         NaT           NaT           NaT        NaT        NaT   \n",
       "5193         NaT           NaT           NaT        NaT        NaT   \n",
       "5194         NaT           NaT           NaT        NaT        NaT   \n",
       "5195         NaT           NaT           NaT        NaT        NaT   \n",
       "5196         NaT           NaT           NaT        NaT        NaT   \n",
       "\n",
       "     disqualified_at  \n",
       "0         2016-09-06  \n",
       "1                NaT  \n",
       "2         2019-01-28  \n",
       "3         2016-09-11  \n",
       "4         2016-09-09  \n",
       "...              ...  \n",
       "5192             NaT  \n",
       "5193             NaT  \n",
       "5194             NaT  \n",
       "5195             NaT  \n",
       "5196             NaT  \n",
       "\n",
       "[5197 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_login_details():\n",
    "    # find .env automagically by walking up directories until it's found\n",
    "    dotenv_path = find_dotenv()\n",
    "    # load up the entries as environment variables\n",
    "    load_dotenv(dotenv_path)\n",
    "    user = os.environ.get(\"DB_USER\")\n",
    "    pw = os.environ.get(\"DB_PW\")\n",
    "    headers = os.environ.get(\"API_HEADERS\")\n",
    "    return user, pw, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to retrieve location of a key in nested data structure\n",
    "\"\"\"\n",
    "\n",
    "def locate_element(data, look_up_elem):\n",
    "    '''\n",
    "    Function to locate the exact location of a an element in a data structure\n",
    "    '''\n",
    "    data_orig = data\n",
    "    loc_list = []\n",
    "\n",
    "    #### Step 1: Create loop: while look_up_elem not in loc_list\n",
    "    while look_up_elem not in loc_list:\n",
    "\n",
    "        data = data_orig\n",
    "        if loc_list != []:\n",
    "            for location in loc_list:\n",
    "                data = data[location]\n",
    "\n",
    "                #### Step 2: Create loop for each element in data.\n",
    "                # This element needs to be appended to loc_list if element is\n",
    "                # found in (sub-levels of) this element\n",
    "\n",
    "        # Combine step 4 and 5 in one function.\n",
    "        # Function is to flatten the data and check if look_up_elem is present in data.\n",
    "        # If element is found, return loc_list\n",
    "        def check_branche(data):\n",
    "            #### Step 2: Check if look_up_element is present on 1st level of data\n",
    "            if look_up_elem in data:\n",
    "                loc_list.append(look_up_elem)\n",
    "                return loc_list\n",
    "\n",
    "            #### Step 3: If element not present on 1st level, filter out strings and integers from data.\n",
    "            # Method is different for different data types\n",
    "            # Note: data_tuple = () (will be problematic, as you cannot append elements to a tuple).\n",
    "            # We may be able to add items from tuple to list as tuple is also a Sequence\n",
    "\n",
    "            # Define data_elements\n",
    "            if isinstance(data, dict):\n",
    "                data_elements = list(data.keys())\n",
    "            elif isinstance(data, list):\n",
    "                data_elements = list(range(len(data)))\n",
    "            # elif type(data)==tuple:\n",
    "            # data_elements = list(range(len(data)))\n",
    "\n",
    "            else:\n",
    "                return \"Element not present\"\n",
    "\n",
    "            for element in data_elements:\n",
    "                data_to_check = data[element]\n",
    "\n",
    "                # Define data_dict, data_list and data_tuple\n",
    "                if isinstance(data_to_check, dict):\n",
    "                    data_dict = data_to_check\n",
    "                    data_list = []\n",
    "                    data_tuple = ()\n",
    "                elif isinstance(data_to_check, list):\n",
    "                    data_dict = {}\n",
    "                    data_list = data_to_check\n",
    "                    data_tuple = ()\n",
    "                elif isinstance(data_to_check, tuple):\n",
    "                    data_dict = {}\n",
    "                    data_list = []\n",
    "                    data_tuple = data_to_check\n",
    "                elif not isinstance(data_to_check, dict) and not isinstance(data_to_check, list) \\\n",
    "                and not isinstance(data_to_check, tuple):\n",
    "                    continue\n",
    "                else:\n",
    "                    return \"Error\"\n",
    "\n",
    "                #### Step 5: Enter while loop (is within the for loop of step 4).\n",
    "                # From the filtered data obtained in step 3, divide the different elements into its data type\n",
    "                # Then, flatten type(data) data type first and then the other two data types\n",
    "                # When look_up_elem is found, append element to loc_list and return loc_list\n",
    "                while data_dict != {} or data_list != [] or data_tuple != ():\n",
    "                    # Flatten dictionary and check if element is present on any of the levels and\n",
    "                    # add list elements to data_list\n",
    "                    # After first round, if any elements were added to data_dict,\n",
    "                    # go through these added elements\n",
    "                    while data_dict != {}:\n",
    "                        if look_up_elem in data_dict:\n",
    "                            loc_list.append(element)\n",
    "                            return\n",
    "\n",
    "                        data_dict_temp = {}\n",
    "                        # Filter the elements in data_dict\n",
    "                        for key, value in iter(data_dict.items()):\n",
    "                            if isinstance(value, dict):\n",
    "                                data_dict_temp.update(value)\n",
    "                            elif isinstance(value, list):\n",
    "                                data_list.append(value)\n",
    "                            # elif isinstance(value, tuple):\n",
    "                            #    test_tuple\n",
    "                            # to check if tuple is also a sequence, can also use chain(element) for this\n",
    "                            else:\n",
    "                                continue\n",
    "                        data_dict = data_dict_temp\n",
    "\n",
    "                    # After data_dict is (temporarily) exhausted, go through data_list\n",
    "                    while data_list != []:\n",
    "                        if look_up_elem in data_list:\n",
    "                            loc_list.append(element)\n",
    "                            return loc_list\n",
    "\n",
    "                        data_list_temp = []\n",
    "                        # Filter the elements in data_dict\n",
    "                        for item in data_list:\n",
    "                            if isinstance(item, dict):\n",
    "                                data_dict.update(item)\n",
    "                            elif isinstance(item, list):\n",
    "                                for idx in item:\n",
    "                                    data_list_temp.append(idx)\n",
    "                            else:\n",
    "                                continue\n",
    "                        data_list = data_list_temp\n",
    "\n",
    "                    # After data_list is (temporarily) exhausted, go through data_tuple\n",
    "                    # while data_tuple !=():\n",
    "                    # Flatten tuple, check if element is present on any of the levels and add dictionary\n",
    "                    # and list elements to data_dict or data_list\n",
    "                    # pass\n",
    "\n",
    "            if look_up_elem not in loc_list:\n",
    "                return \"Element not Found\"\n",
    "\n",
    "        check_branche(data)\n",
    "    return loc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'key1':1, 'key2':[1,2,3,[1,2,3,{'key5':5}]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element is string or integer\n",
      "Element is string or integer\n",
      "Element is string or integer\n",
      "Element is string or integer\n",
      "Element is string or integer\n",
      "Element is string or integer\n",
      "Element is string or integer\n",
      "Element is string or integer\n",
      "Element is string or integer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['key2', 3, 3, 'key5']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locate_element(a, 'key5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = [\n",
    "        'id',\n",
    "        'name',\n",
    "        'firstname',\n",
    "        'lastname',\n",
    "        'headline',\n",
    "        'subdomain', \n",
    "        'shortcode',\n",
    "        'title',\n",
    "        'stage',\n",
    "        'disqualified',\n",
    "        'disqualification_reason',\n",
    "        'hired_at',\n",
    "        'sourced',\n",
    "        'profile_url',\n",
    "        'address',\n",
    "        'phone',\n",
    "        'email',\n",
    "        'domain',\n",
    "        'created_at',\n",
    "        'updated_at',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_api_entry(url, headers):\n",
    "    '''\n",
    "    Function to retrieve the last entry in Workable through API\n",
    "    \n",
    "    Inputs:\n",
    "    url: url of the Workable API\n",
    "    headers: headers to connect to the API\n",
    "    \n",
    "    Outputs:\n",
    "    'id' of the last entry\n",
    "    '''\n",
    "    section = 'candidates?'\n",
    "    limit='100'\n",
    "    d = datetime.datetime.today()\n",
    "    r_last_entry = requests.get(url+section+'limit='+limit+'&created_after='+d.isoformat()+'.json', headers=headers)\n",
    "    while len(r_last_entry.json()['candidates'])==0:\n",
    "        d = (d - datetime.timedelta(days=1))\n",
    "        r_last_entry = requests.get(url+section+'limit='+limit+'&created_after='+d.isoformat()+'.json', headers=headers)\n",
    "        time.sleep(0.9)\n",
    "    last_id = r_last_entry.json()['candidates'][-1]['id']\n",
    "    return last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_last_db_entry(pw, db_name=\"candidates\", user='root', host='127.0.0.1', port='', database='recruitment_dashboard'):\n",
    "    '''\n",
    "    Function to retrieve candidate id of the last entry in the MySQL DB\n",
    "    Inputs:\n",
    "    db_name: Name of the to be created MySQL DB (default is 'candidates2')\n",
    "    user: user name of db (default is 'root')\n",
    "    pw: password of database\n",
    "    host = '127.0.0.1' if connecting to local DB\n",
    "    host = '<IP address of DB>' if connecting to a DB hosted externally\n",
    "    port: port (default is no port specified). Format is: ':<port>'\n",
    "    database: database schema name\n",
    "    \n",
    "    Outputs:\n",
    "    last_entry_id: 'id' of last entry in the MySQL DB\n",
    "    '''\n",
    "    conn = mysql.connector.connect(user=user, password=pw,host=host, database=database)\n",
    "    cursor = conn.cursor()\n",
    "    sql_select_query = \"\"\"SELECT id FROM %s ORDER BY created_at DESC LIMIT 1\"\"\"%(db_name)\n",
    "    cursor.execute(sql_select_query)\n",
    "    last_entry_id = cursor.fetchall() \n",
    "    last_entry_id = last_entry_id[0][0]\n",
    "    conn.close()\n",
    "    return last_entry_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cand_data(df_dict, key_list, url, headers, cand_id_list=None, start_id='', start_date=''):\n",
    "    if cand_id_list is None:\n",
    "        cand_id_list = []\n",
    "    if start_date != '':\n",
    "        created_after = '&created_after='+start_date\n",
    "    else:\n",
    "        created_after = ''\n",
    "    \n",
    "    if start_id != '':\n",
    "        start_id = '&since_id='+start_id\n",
    "    else:\n",
    "        start_id = ''\n",
    "    section = 'candidates?'\n",
    "    limit='100'\n",
    "    request = requests.get(url+section+'limit='+limit+created_after+start_id+'.json', headers=headers)  \n",
    "    for cand in request.json()['candidates']:\n",
    "        cand_id_list.append(cand['id'])\n",
    "        for k in key_list:\n",
    "            loc = locate_element(cand,k)\n",
    "            v = cand\n",
    "            for i in loc:\n",
    "                v = v[i]\n",
    "            df_dict[k].append(v)\n",
    "    try:\n",
    "        since_id=request.json()['paging']['next'].split(\"since_id=\",1)[1]\n",
    "        return df_dict, since_id, cand_id_list\n",
    "    except:\n",
    "        since_id=None\n",
    "        return df_dict, since_id, cand_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={'Authorization': 'Bearer 229aa3876e4fc4447460a13da7f57d1be4111202e1d56d4d0231fb932c1e7cd1'}\n",
    "url = 'https://jdriven.workable.com/spi/v3/'\n",
    "df_dict = {}\n",
    "for key in key_list:\n",
    "    df_dict[key]=[]\n",
    "df_check, since_id, cand_id_list = get_cand_data(df_dict, key_list, url, headers, cand_id_list=None, start_id='', start_date='')\n",
    "#df_dict_candidate_act = retrieve_activities(url, headers, cand_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['ddb204',\n",
       "  'ddb571',\n",
       "  'ddb572',\n",
       "  'ddb582',\n",
       "  'ddb9ca',\n",
       "  'ddbfa2',\n",
       "  'ddf173',\n",
       "  'ddf20e',\n",
       "  'ddf485',\n",
       "  'ddf4cd',\n",
       "  'ddf4d2',\n",
       "  'ddf7b4',\n",
       "  'ddfcbd',\n",
       "  'ddfe84',\n",
       "  'de4088',\n",
       "  'de4522',\n",
       "  'de463d',\n",
       "  'de47a3',\n",
       "  'de489d',\n",
       "  'de53cd',\n",
       "  'de5bfa',\n",
       "  'de5d64',\n",
       "  'df6c94',\n",
       "  'df77d7',\n",
       "  'df78b9',\n",
       "  'df87cf',\n",
       "  'df8812',\n",
       "  'dfaacc',\n",
       "  'dfaf18',\n",
       "  'e00269',\n",
       "  'e01304',\n",
       "  'e01384',\n",
       "  'e03bca',\n",
       "  'e096e5',\n",
       "  'e11c35',\n",
       "  'e12f8f',\n",
       "  'e1cca6',\n",
       "  'e23fde',\n",
       "  'e27389',\n",
       "  'e2d0e6',\n",
       "  'e2d1ee',\n",
       "  'e2d3f3',\n",
       "  'e2d4ac',\n",
       "  'e2d5c4',\n",
       "  'e2d75b',\n",
       "  'e2e573',\n",
       "  'e3016e',\n",
       "  'e36bc6',\n",
       "  'e37c6f',\n",
       "  'e3c572',\n",
       "  'e48b5d',\n",
       "  'e48ca1',\n",
       "  'e48dcf',\n",
       "  'e48e52',\n",
       "  'e4f7dd',\n",
       "  'e50701',\n",
       "  'e51018',\n",
       "  'e58576',\n",
       "  'e5a36a',\n",
       "  'e62144',\n",
       "  'e625d1',\n",
       "  'e626f8',\n",
       "  'e638d2',\n",
       "  'e66728',\n",
       "  'e67a26',\n",
       "  'e67b0f',\n",
       "  'e67bb3',\n",
       "  'e67d9a',\n",
       "  'e6af5b',\n",
       "  'e6bf82',\n",
       "  'e6c2b9',\n",
       "  'e6c31d',\n",
       "  'e6c355',\n",
       "  'e7d4fb',\n",
       "  'e7e78e',\n",
       "  'e7fb23',\n",
       "  'e8132b',\n",
       "  'e81351',\n",
       "  'e86ad3',\n",
       "  'e86bc0',\n",
       "  'e875d1',\n",
       "  'e88844',\n",
       "  'e991c1',\n",
       "  'e991e5',\n",
       "  'e99a03',\n",
       "  'e9a3af',\n",
       "  'e9a3b0',\n",
       "  'ea0e8f',\n",
       "  'ea1045',\n",
       "  'ea178d',\n",
       "  'ea22b7',\n",
       "  'eacf37',\n",
       "  'eacfad',\n",
       "  'eacfe0',\n",
       "  'ead014',\n",
       "  'ead061',\n",
       "  'eb1555',\n",
       "  'eb2cf8',\n",
       "  'eb4afd',\n",
       "  'ebb4b0'],\n",
       " 'name': ['Niels Drost',\n",
       "  'Paula L Amaral Santos',\n",
       "  'Gulliver de Boer',\n",
       "  'Pieter Kouyzer',\n",
       "  'Profiel Van Aris Koning',\n",
       "  'Casper Rooker',\n",
       "  'Lennert Gijsen',\n",
       "  'Serge Juchko',\n",
       "  'Roel Theeuwen',\n",
       "  'Hasan Kurt',\n",
       "  'Bert de Vreugd',\n",
       "  'Amin Ziarkash',\n",
       "  'Almar Schouten',\n",
       "  'Bastiaan Grisèl',\n",
       "  'Thijs Immink',\n",
       "  'Robin Dronkers',\n",
       "  'Willem Ottenheijm',\n",
       "  'Stefan Tol',\n",
       "  'Sieb Van Keppel',\n",
       "  'Contracten recruiters',\n",
       "  'Jan Vries Lentsch',\n",
       "  'Johannes Ransijn',\n",
       "  'Erwin Van Eyk',\n",
       "  'Coskun Dag',\n",
       "  'Curriculum Vitae Kengyip Lee',\n",
       "  'Yalda Mohammadian',\n",
       "  'Matthijs Brouns',\n",
       "  'Rutger de Graaf',\n",
       "  'Shoaib Amini',\n",
       "  'Veli Aydin',\n",
       "  'Bram Neijt',\n",
       "  'Tim van Grieken',\n",
       "  'Dave Van Eijck',\n",
       "  'Roy De Groot',\n",
       "  'Mark Oost',\n",
       "  'Uri Shimron',\n",
       "  'Jeffrey Powell',\n",
       "  'Bert Carsouw',\n",
       "  'Marc Huls',\n",
       "  'Pim Schellart',\n",
       "  'Sander Kerkdijk',\n",
       "  'Kia Eisinga',\n",
       "  'Kaitlin Nadson',\n",
       "  'Juan Adriaanse',\n",
       "  'Mar Maykel Vink',\n",
       "  'Lucas Maasse',\n",
       "  'Benjamin Van Den Akker',\n",
       "  'Dana Bˇalibanu',\n",
       "  'Mark Vervuurt',\n",
       "  'Pearl Roman',\n",
       "  'Matthijs van der Kroon',\n",
       "  'Anthony Potappel',\n",
       "  'Sietse T. Au',\n",
       "  'Joost Heijkoop',\n",
       "  'Thierry Quirijn Mentzel',\n",
       "  'Wibo Pipping',\n",
       "  'Dimitri Pater',\n",
       "  'Gerard Simons',\n",
       "  'Ir Joost Van Veen',\n",
       "  'Jeroen Vlek',\n",
       "  'Ian FitzPatrick',\n",
       "  'Hessel Miedema',\n",
       "  'Fabian Voorter',\n",
       "  'Front-End Developer',\n",
       "  'Saskia Koldijk',\n",
       "  'Roland De Boo',\n",
       "  'Chris Blom',\n",
       "  'Christopher Tunnell',\n",
       "  'Rob Driessen',\n",
       "  'Edward Brinkmann',\n",
       "  'Jorrit Glastra',\n",
       "  'Malcolm Halfhuid',\n",
       "  'Wilco Koorn',\n",
       "  'Abel Flos',\n",
       "  'Misha Veldhoen',\n",
       "  'frank kurstjens',\n",
       "  'Dennis Bullee',\n",
       "  'Niels Renard',\n",
       "  'Jorden Schrama',\n",
       "  'Charalampos Sarantopoulos',\n",
       "  'Roel Nieuwenhuizen',\n",
       "  'Anton Bossenbroek',\n",
       "  'Boris Reuderink',\n",
       "  'Sjoerd de Haan',\n",
       "  'Laurens Koppenol',\n",
       "  'Daniel Profiel',\n",
       "  'Michel Capelle',\n",
       "  'Simon van der Zon',\n",
       "  'Julian Vos',\n",
       "  'Jeroen Dalhuisen',\n",
       "  'Rick Slangen',\n",
       "  'Daan Debie',\n",
       "  'Bart Jeukendrup',\n",
       "  'Paul Bormans',\n",
       "  'Michiel Moonen',\n",
       "  'Karsten Meinster',\n",
       "  'Hassane Barre',\n",
       "  'Gebrekirstos G Gebremeskel',\n",
       "  'Tim van Elteren',\n",
       "  'Danielle McCool'],\n",
       " 'firstname': ['Niels',\n",
       "  'Paula L',\n",
       "  'Gulliver',\n",
       "  'Pieter',\n",
       "  'Profiel Van Aris',\n",
       "  'Casper',\n",
       "  'Lennert',\n",
       "  'Serge',\n",
       "  'Roel',\n",
       "  'Hasan',\n",
       "  'Bert',\n",
       "  'Amin',\n",
       "  'Almar',\n",
       "  'Bastiaan',\n",
       "  'Thijs',\n",
       "  'Robin',\n",
       "  'Willem',\n",
       "  'Tol',\n",
       "  'Sieb Van',\n",
       "  'Contracten',\n",
       "  'Jan',\n",
       "  'Johannes',\n",
       "  'Erwin Van',\n",
       "  'Dag',\n",
       "  'Lee',\n",
       "  'Yalda',\n",
       "  'Matthijs',\n",
       "  'Rutger',\n",
       "  'Shoaib',\n",
       "  'Veli',\n",
       "  'Bram',\n",
       "  'Tim Van',\n",
       "  'Dave Van',\n",
       "  'Roy De',\n",
       "  'Mark',\n",
       "  'Uri',\n",
       "  'Jeffrey',\n",
       "  'Bert',\n",
       "  'Marc',\n",
       "  'Pim',\n",
       "  'Sander',\n",
       "  'Kia',\n",
       "  'Kaitlin',\n",
       "  'Juan',\n",
       "  'Mar',\n",
       "  'Lucas',\n",
       "  'Benjamin Van Den',\n",
       "  'Dana',\n",
       "  'Mark',\n",
       "  'Pearl',\n",
       "  'Matthijs Van Der',\n",
       "  'Anthony',\n",
       "  'Sietse T',\n",
       "  'Joost',\n",
       "  'Thierry',\n",
       "  'Wibo',\n",
       "  'Dimitri',\n",
       "  'Gerard',\n",
       "  'Ir Joost Van',\n",
       "  'Jeroen',\n",
       "  'Ian',\n",
       "  'Hessel',\n",
       "  'Fabian',\n",
       "  'Front-End',\n",
       "  'Saskia',\n",
       "  'Roland De',\n",
       "  'Chris',\n",
       "  'Christopher',\n",
       "  'Rob',\n",
       "  'Edward',\n",
       "  'Jorrit',\n",
       "  'Malcolm',\n",
       "  'Wilco',\n",
       "  'Abel',\n",
       "  'Misha',\n",
       "  'Frank',\n",
       "  'Dennis',\n",
       "  'Niels',\n",
       "  'Jorden',\n",
       "  'Charalampos',\n",
       "  'Roel',\n",
       "  'Anton',\n",
       "  'Boris',\n",
       "  'Sjoerd',\n",
       "  'Laurens',\n",
       "  'Daniel',\n",
       "  'Michel',\n",
       "  'Simon',\n",
       "  'Julian',\n",
       "  'Jeroen',\n",
       "  'Rick',\n",
       "  'Daan',\n",
       "  'Bart',\n",
       "  'Paul',\n",
       "  'Michiel',\n",
       "  'Karsten',\n",
       "  'Hassane',\n",
       "  'Gebrekirstos G',\n",
       "  'Tim',\n",
       "  'Danielle'],\n",
       " 'lastname': ['Drost',\n",
       "  'Amaral Santos',\n",
       "  'de Boer',\n",
       "  'Kouyzer',\n",
       "  'Koning',\n",
       "  'Rooker',\n",
       "  'Gijsen',\n",
       "  'Juchko',\n",
       "  'Theeuwen',\n",
       "  'Kurt',\n",
       "  'de Vreugd',\n",
       "  'Ziarkash',\n",
       "  'Schouten',\n",
       "  'Grisèl',\n",
       "  'Immink',\n",
       "  'Dronkers',\n",
       "  'Ottenheijm',\n",
       "  'Stefan',\n",
       "  'Keppel',\n",
       "  'recruiters',\n",
       "  'Vries Lentsch',\n",
       "  'Ransijn',\n",
       "  'Eyk',\n",
       "  'Coskun',\n",
       "  'Curriculum Vitae Kengyip',\n",
       "  'Mohammadian',\n",
       "  'Brouns',\n",
       "  'de Graaf',\n",
       "  'Amini',\n",
       "  'Aydin',\n",
       "  'Neijt',\n",
       "  'Grieken',\n",
       "  'Eijck',\n",
       "  'Groot',\n",
       "  'Oost',\n",
       "  'Shimron',\n",
       "  'Powell',\n",
       "  'Carsouw',\n",
       "  'Huls',\n",
       "  'Schellart',\n",
       "  'Kerkdijk',\n",
       "  'Eisinga',\n",
       "  'Nadson',\n",
       "  'Adriaanse',\n",
       "  'Maykel Vink',\n",
       "  'Maasse',\n",
       "  'Akker',\n",
       "  'Bˇalibanu',\n",
       "  'Vervuurt',\n",
       "  'Roman',\n",
       "  'Kroon',\n",
       "  'Potappel',\n",
       "  'Au',\n",
       "  'Heijkoop',\n",
       "  'Quirijn Mentzel',\n",
       "  'Pipping',\n",
       "  'Pater',\n",
       "  'Simons',\n",
       "  'Veen',\n",
       "  'Vlek',\n",
       "  'Fitzpatrick',\n",
       "  'Miedema',\n",
       "  'Voorter',\n",
       "  'Developer',\n",
       "  'Koldijk',\n",
       "  'Boo',\n",
       "  'Blom',\n",
       "  'Tunnell',\n",
       "  'Driessen',\n",
       "  'Brinkmann',\n",
       "  'Glastra',\n",
       "  'Halfhuid',\n",
       "  'Koorn',\n",
       "  'Flos',\n",
       "  'Veldhoen',\n",
       "  'Kurstjens',\n",
       "  'Bullee',\n",
       "  'Renard',\n",
       "  'Schrama',\n",
       "  'Sarantopoulos',\n",
       "  'Nieuwenhuizen',\n",
       "  'Bossenbroek',\n",
       "  'Reuderink',\n",
       "  'de Haan',\n",
       "  'Koppenol',\n",
       "  'Profiel',\n",
       "  'Capelle',\n",
       "  'van der Zon',\n",
       "  'Vos',\n",
       "  'Dalhuisen',\n",
       "  'Slangen',\n",
       "  'Debie',\n",
       "  'Jeukendrup',\n",
       "  'Bormans',\n",
       "  'Moonen',\n",
       "  'Meinster',\n",
       "  'Barre',\n",
       "  'Gebremeskel',\n",
       "  'van Elteren',\n",
       "  'McCool'],\n",
       " 'headline': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Software Developer at Qualogy',\n",
       "  'Software Architect Frontend at Powerhouse Bv',\n",
       "  'Data Science & Technology MSc student',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Web Analytics, Data Science and Social Psychology.',\n",
       "  'Senior Developer at 42.nl',\n",
       "  'Data Analytics Consultant & Data Science Analyst',\n",
       "  None,\n",
       "  'Senior data-analist at Coney',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Data Scientist @ Aneto BV Bunnink',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Senior Big Data / Java Consultant at Capgemini',\n",
       "  None,\n",
       "  'Data Scientist at RTL Nederland',\n",
       "  'Big Data enthusiast at Vancis | Cloud | Software Defined * | Automation | Hadoop | OpenStack | Linux',\n",
       "  'Software Engineer',\n",
       "  'Software Consultant / Full Stack Developer at DHL',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Data Scientist at Qualogy',\n",
       "  'gpa',\n",
       "  'Anchormen',\n",
       "  'Post Doctoral researcher: Neuroscience of language and bilingualism',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Cognitive Artificial Intelligence Expert bij Sense Health BV',\n",
       "  'Software Architect | Java, Cloud, Sensor Networks, Event Processing',\n",
       "  'Software Engineer at ADGOJI',\n",
       "  'Physicist and founder Snooty Analytics',\n",
       "  None,\n",
       "  None,\n",
       "  'Senior Reservoir Engineer',\n",
       "  'Business Intelligence Consultant',\n",
       "  'Lead developer / Senior Agile Consultant',\n",
       "  None,\n",
       "  'Scientific Software Engineer and Data Scientist',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Machine Learning Consultant at Cortext',\n",
       "  'Machine learning devoper at ING',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Freelance Software Engineer / Data Engineer / Firestarter at Joy in Coding',\n",
       "  'Founder at Infty - Data scientist, software architect',\n",
       "  'oce technologies',\n",
       "  None,\n",
       "  'Mission Critical Engineer @ Schuberg Philis',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'subdomain': ['jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven',\n",
       "  'jdriven'],\n",
       " 'shortcode': ['A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '9882E4C0EA',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '9882E4C0EA',\n",
       "  '9882E4C0EA',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  'A8C5321F60',\n",
       "  'F2E5FDE7A5',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  '9882E4C0EA',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  '9882E4C0EA',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  '9882E4C0EA',\n",
       "  'F2E5FDE7A5',\n",
       "  '46F9A9BEBD',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'F2E5FDE7A5',\n",
       "  '46F9A9BEBD',\n",
       "  'F2E5FDE7A5',\n",
       "  'F17EA1F924',\n",
       "  'F17EA1F924',\n",
       "  'F2E5FDE7A5',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  'F2E5FDE7A5',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  'F17EA1F924',\n",
       "  '8176464B66',\n",
       "  '8176464B66',\n",
       "  'A8C5321F60',\n",
       "  'F17EA1F924',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  '46F9A9BEBD',\n",
       "  '9882E4C0EA',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'F2E5FDE7A5',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60',\n",
       "  '46F9A9BEBD',\n",
       "  'A8C5321F60',\n",
       "  'A8C5321F60',\n",
       "  'F17EA1F924',\n",
       "  'A8C5321F60',\n",
       "  'F2E5FDE7A5',\n",
       "  'F2E5FDE7A5',\n",
       "  'F17EA1F924',\n",
       "  '46F9A9BEBD',\n",
       "  'F2E5FDE7A5',\n",
       "  'F2E5FDE7A5',\n",
       "  'A8C5321F60'],\n",
       " 'title': ['Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Java Developer (JDriven)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Java Developer (JDriven)',\n",
       "  'Java Developer (JDriven)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Java Developer (JDriven)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Java Developer (JDriven)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Java Developer (JDriven)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Architect',\n",
       "  'Big Data Architect',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Architect',\n",
       "  'Front-End Developer (Divotion)',\n",
       "  'Front-End Developer (Divotion)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Architect',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Java Developer (JDriven)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Architect',\n",
       "  'Big Data Scientist (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Architect',\n",
       "  'Jr. Java Developer (JCore)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Engineer (BDR)',\n",
       "  'Big Data Scientist (BDR)'],\n",
       " 'stage': ['1st Interview',\n",
       "  'Hired',\n",
       "  '2nd Interview',\n",
       "  'Talentpool',\n",
       "  '2nd Interview',\n",
       "  'Hired',\n",
       "  'Hired',\n",
       "  'Talentpool',\n",
       "  'Talentpool',\n",
       "  '1st Interview',\n",
       "  'Talentpool',\n",
       "  '2nd Interview',\n",
       "  'Talentpool',\n",
       "  'Talentpool',\n",
       "  '1st Interview',\n",
       "  'Sourced',\n",
       "  'Sourced',\n",
       "  'Sourced',\n",
       "  'To schedule',\n",
       "  'Talentpool',\n",
       "  'Review',\n",
       "  '1st Interview',\n",
       "  'Talentpool',\n",
       "  'Sourced',\n",
       "  'Review',\n",
       "  'Sourced',\n",
       "  '1st Interview',\n",
       "  'To schedule',\n",
       "  '1st Interview',\n",
       "  'Sourced',\n",
       "  'Hired',\n",
       "  'Sourced',\n",
       "  'To schedule',\n",
       "  'Review',\n",
       "  'Review',\n",
       "  'Applied',\n",
       "  '2nd Interview',\n",
       "  'Sourced',\n",
       "  '1st Interview',\n",
       "  'Shortlisted',\n",
       "  'Talentpool',\n",
       "  'Review',\n",
       "  'Sourced',\n",
       "  'To schedule',\n",
       "  'Review',\n",
       "  '1st Interview',\n",
       "  '1st Interview',\n",
       "  'Talentpool',\n",
       "  'Applied',\n",
       "  '1st Interview',\n",
       "  'Applied',\n",
       "  'Sourced',\n",
       "  'Applied',\n",
       "  'Applied',\n",
       "  'Sourced',\n",
       "  'Sourced',\n",
       "  'Review',\n",
       "  '1st Interview',\n",
       "  '1st Interview',\n",
       "  'Applied',\n",
       "  'Talentpool',\n",
       "  'Talentpool',\n",
       "  'Talentpool',\n",
       "  'To schedule',\n",
       "  'Applied',\n",
       "  'Applied',\n",
       "  'Shortlisted',\n",
       "  'Applied',\n",
       "  'Sourced',\n",
       "  '1st Interview',\n",
       "  '1st Interview',\n",
       "  'Sourced',\n",
       "  'Talentpool',\n",
       "  'Sourced',\n",
       "  'Applied',\n",
       "  'Applied',\n",
       "  'Review',\n",
       "  'Talentpool',\n",
       "  'Talentpool',\n",
       "  'Sourced',\n",
       "  '1st Interview',\n",
       "  'Talentpool',\n",
       "  'Applied',\n",
       "  'Talentpool',\n",
       "  '1st Interview',\n",
       "  'Sourced',\n",
       "  'Review',\n",
       "  'Talentpool',\n",
       "  'Review',\n",
       "  'Review',\n",
       "  'Review',\n",
       "  'Applied',\n",
       "  'Applied',\n",
       "  'Review',\n",
       "  'Applied',\n",
       "  'Applied',\n",
       "  'Sourced',\n",
       "  'Review',\n",
       "  '1st Interview',\n",
       "  'Review'],\n",
       " 'disqualified': [True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True],\n",
       " 'disqualification_reason': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'hired_at': [None,\n",
       "  '2016-10-14T10:04:42Z',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '2016-09-23T14:20:02Z',\n",
       "  '2016-09-29T08:28:40Z',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '2016-10-04T11:02:37Z',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'sourced': [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True],\n",
       " 'profile_url': ['https://jdriven.workable.com/backend/jobs/329280/candidates/14527794',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14528671',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14528672',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14528688',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14529784',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14531280',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14544033',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14544188',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14544819',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14544891',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14544896',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14545634',\n",
       "  'https://jdriven.workable.com/backend/jobs/331510/candidates/14546923',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14547378',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14564278',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14565456',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14565739',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14566097',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14566347',\n",
       "  'https://jdriven.workable.com/backend/jobs/331510/candidates/14569211',\n",
       "  'https://jdriven.workable.com/backend/jobs/331510/candidates/14571304',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14571666',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14641090',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14643973',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14644199',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14648061',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14648128',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14657018',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14658118',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14679447',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14683698',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14683826',\n",
       "  'https://jdriven.workable.com/backend/jobs/331510/candidates/14694136',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14717459',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14751587',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14756541',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14796756',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14826252',\n",
       "  'https://jdriven.workable.com/backend/jobs/331510/candidates/14839479',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14863380',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14863644',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14864161',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14864346',\n",
       "  'https://jdriven.workable.com/backend/jobs/331510/candidates/14864626',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14865033',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14868641',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14875804',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/14903028',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14907293',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/14925984',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14976651',\n",
       "  'https://jdriven.workable.com/backend/jobs/331678/candidates/14976975',\n",
       "  'https://jdriven.workable.com/backend/jobs/331678/candidates/14977277',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/14977408',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15004427',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15008303',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15010630',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15040676',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15048344',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15080562',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15081727',\n",
       "  'https://jdriven.workable.com/backend/jobs/331678/candidates/15082022',\n",
       "  'https://jdriven.workable.com/backend/jobs/340395/candidates/15086592',\n",
       "  'https://jdriven.workable.com/backend/jobs/340395/candidates/15098454',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15103316',\n",
       "  'https://jdriven.workable.com/backend/jobs/331678/candidates/15103549',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15103713',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15104200',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/15116937',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/15121072',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15121895',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15121995',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15122051',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15192105',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15196860',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15201873',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/15208025',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/15208063',\n",
       "  'https://jdriven.workable.com/backend/jobs/331510/candidates/15230465',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15230702',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/15233279',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15238002',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15305967',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15306003',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15308081',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15310557',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15310558',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15337917',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/15338355',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15340219',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15343077',\n",
       "  'https://jdriven.workable.com/backend/jobs/331678/candidates/15387237',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15387355',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15387406',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15387458',\n",
       "  'https://jdriven.workable.com/backend/jobs/331678/candidates/15387535',\n",
       "  'https://jdriven.workable.com/backend/jobs/331519/candidates/15405187',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15411238',\n",
       "  'https://jdriven.workable.com/backend/jobs/331681/candidates/15418923',\n",
       "  'https://jdriven.workable.com/backend/jobs/329280/candidates/15445982'],\n",
       " 'address': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'The Hague Area, Netherlands',\n",
       "  'Utrecht Area, Netherlands',\n",
       "  'Delft, Provincie Zuid-Holland, Nederland',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Amsterdam, North Holland, Netherlands',\n",
       "  'Den Haag en omgeving, Nederland',\n",
       "  'Utrecht en omgeving, Nederland',\n",
       "  None,\n",
       "  'The Hague, South Holland',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Utrecht, Netherlands',\n",
       "  None,\n",
       "  'San Francisco, California, United States',\n",
       "  'Amsterdam, North Holland, Netherlands',\n",
       "  'Den Haag en omgeving, Nederland',\n",
       "  'Amsterdam, Netherlands',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Rotterdam, South Holland, Netherlands',\n",
       "  'Netherlands',\n",
       "  None,\n",
       "  'Nijmegen, Gelderland, Netherlands',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Utrecht Area, Netherlands',\n",
       "  'Rotterdam, South Holland, Netherlands',\n",
       "  None,\n",
       "  'Amsterdam, North Holland, Netherlands',\n",
       "  None,\n",
       "  None,\n",
       "  'Aberdeen, Scotland, United Kingdom',\n",
       "  'Utrecht en omgeving, Nederland',\n",
       "  'Amsterdam, Provincie Noord-Holland, Netherlands',\n",
       "  None,\n",
       "  'Utrecht Area, Netherlands',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Utrecht, Netherlands',\n",
       "  'Groningen en omgeving, Nederland',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Amsterdam, North Holland, Netherlands',\n",
       "  'Amsterdam Area, Netherlands',\n",
       "  'Eindhoven Area, Netherlands',\n",
       "  None,\n",
       "  'Den Haag en omgeving, Nederland',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'phone': ['+31 6 1543 4021',\n",
       "  None,\n",
       "  '+31612085780',\n",
       "  '+31(0)85 0020019',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '0625642501',\n",
       "  '495 310 0184',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+44 7 44 77 19 31 5',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+31 (0)858882905',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+31 6 14563955',\n",
       "  '(020) 2401 401',\n",
       "  None,\n",
       "  None,\n",
       "  '23955-6900',\n",
       "  None,\n",
       "  '+31612255344',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '(020) 2401 401',\n",
       "  '+31888963850',\n",
       "  '+31622924942',\n",
       "  None,\n",
       "  None,\n",
       "  '+1 (609) 356-4519',\n",
       "  '06-22 55 71 92',\n",
       "  None,\n",
       "  '+31 (0)6 136 294 81',\n",
       "  '285 97 272',\n",
       "  None,\n",
       "  '0655967587',\n",
       "  '06 44872734',\n",
       "  '+31 (627) 206 495',\n",
       "  None,\n",
       "  '+31619424969',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+31654724248',\n",
       "  '+316 30 11 97 10',\n",
       "  None,\n",
       "  '06 538 606 42',\n",
       "  '0613387450',\n",
       "  None,\n",
       "  None,\n",
       "  '+44 7478 945 418',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+31 6 3918 6612',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+31616355456',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+31628198643',\n",
       "  '(+31) 0647401851',\n",
       "  None,\n",
       "  '+1 646 919 6539',\n",
       "  None,\n",
       "  None,\n",
       "  '06-42145808',\n",
       "  None,\n",
       "  None,\n",
       "  '+31611799349',\n",
       "  None,\n",
       "  '+31 6 24890046',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '+31 (0)858882905',\n",
       "  '+31647270950',\n",
       "  None,\n",
       "  None],\n",
       " 'email': ['niels.drost@gmail.com',\n",
       "  'paula.amrl@gmail.com',\n",
       "  'gulif87@hotmail.com',\n",
       "  'joris.braspenning@careerresult.nl',\n",
       "  'frank.kurstjens@jdriven.com',\n",
       "  'casper.rooker@gmail.com',\n",
       "  'ellis@fahr-becker.nl',\n",
       "  None,\n",
       "  'roel.theeuwen@gmail.com',\n",
       "  'ict@aatop.nl',\n",
       "  'bertdvreugd@msn.com',\n",
       "  'a.ziarkash@gmail.com',\n",
       "  'almar.schouten@yahoo.com',\n",
       "  'bastiaan.grisel@gmail.com',\n",
       "  'r.out@java-professionals.nl',\n",
       "  'robin.dronkers.werk@gmail.com',\n",
       "  'willemottenheijm@gmail.com',\n",
       "  'tolstefan@hotmail.com',\n",
       "  'sieb.van.keppel@mail.com',\n",
       "  None,\n",
       "  None,\n",
       "  'bram@careervalue.nl',\n",
       "  'erwinvaneyk@gmail.com',\n",
       "  None,\n",
       "  'kengyiplee@gmail.com',\n",
       "  None,\n",
       "  'matthijs.brouns@gmail.com',\n",
       "  None,\n",
       "  'renee.moerenhout+shoaibamini@jdriven.com',\n",
       "  'v_aydin@live.nl',\n",
       "  'bneijt@gmail.com',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'shimron@localinfo.nl',\n",
       "  'farid@careervalue.nl',\n",
       "  None,\n",
       "  'jvandiest@spilberg.nl',\n",
       "  'p.schellart@princeton.edu',\n",
       "  'sander.kerkdijk@aneto.nl',\n",
       "  'kiaeisinga@gmail.com',\n",
       "  'kaitlin.nadson@gmail.com',\n",
       "  'adriaanse.juan@gmail.nl',\n",
       "  'maykel@maykelvink.nl',\n",
       "  'lucasmaasse@gmail.com',\n",
       "  'benjaminvandenakker@gmail.com',\n",
       "  'danabalibanu@gmail.com',\n",
       "  'm.a.vervuurt@gmail.com',\n",
       "  'pearlroman@hotmail.com',\n",
       "  'mvdkroon@gmail.com',\n",
       "  'apotappel@itslogic.nl',\n",
       "  None,\n",
       "  'leipie@gmail.com',\n",
       "  't.q.mentzel@gmail.com',\n",
       "  'wibo.pipping@gmail.com',\n",
       "  None,\n",
       "  'sjrasimons@gmail.com',\n",
       "  'gpabna@icloud.com',\n",
       "  None,\n",
       "  'ian@ianfitzpatrick.eu',\n",
       "  'hessel.miedema@gmail.com',\n",
       "  'e.wagemaker@java-professionals.nl',\n",
       "  None,\n",
       "  None,\n",
       "  'rolanddeboo@gmail.com',\n",
       "  'chrisblom@chrisblom.net',\n",
       "  'ctunnell@nikhef.nl',\n",
       "  'driessen@hotmail.com',\n",
       "  'edward.brinkmann@gmail.com',\n",
       "  'jorrit.glastra@wingit.nl',\n",
       "  None,\n",
       "  'wkoorn@xebia.com',\n",
       "  'abel.flos@gmail.com',\n",
       "  'misha.veldhoen@gmail.com',\n",
       "  'frank.kurstjens@jdriven.com',\n",
       "  'dennisbullee@hotmail.com',\n",
       "  'nmdrenard@gmail.com',\n",
       "  'jordenschrama@hotmail.com',\n",
       "  'charalampos.sarantopoulos@gmail.com',\n",
       "  'jvandiest@spilberg.nl',\n",
       "  'anton.bossenbroek@me.com',\n",
       "  'b.reuderink@gmail.com',\n",
       "  'sjdh@xs4all.nl',\n",
       "  'renee.moerenhout@bigdatarepublic.nl',\n",
       "  None,\n",
       "  'michel@michelcapelle.nl',\n",
       "  'simonvanderzon@hotmail.com',\n",
       "  'julianvosje@gmail.com',\n",
       "  'jdalhuisen@hotmail.com',\n",
       "  None,\n",
       "  'debie.daan@gmail.com',\n",
       "  'bartjeukendrup@elooglobal.com',\n",
       "  'paul.bormans@oce.com',\n",
       "  None,\n",
       "  None,\n",
       "  'hasbarre@gmail.com',\n",
       "  'gebre@cwi.nl',\n",
       "  'ovidiu.terinte@astburymarsden.com',\n",
       "  None],\n",
       " 'domain': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'search',\n",
       "  'search',\n",
       "  'search',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'search',\n",
       "  'search',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'search',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'search',\n",
       "  'search',\n",
       "  'unknown',\n",
       "  'search',\n",
       "  None,\n",
       "  None,\n",
       "  'search',\n",
       "  'search',\n",
       "  'search',\n",
       "  None,\n",
       "  None,\n",
       "  'indeed.com',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'search',\n",
       "  'search',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'search',\n",
       "  'search',\n",
       "  'search',\n",
       "  'unknown',\n",
       "  'search',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'created_at': ['2016-09-05T10:05:28Z',\n",
       "  '2016-09-05T10:51:00Z',\n",
       "  '2016-09-05T10:51:04Z',\n",
       "  '2016-09-05T10:52:07Z',\n",
       "  '2016-09-05T11:49:31Z',\n",
       "  '2016-09-05T13:07:18Z',\n",
       "  '2016-09-05T18:40:42Z',\n",
       "  '2016-09-05T18:48:10Z',\n",
       "  '2016-09-05T19:17:50Z',\n",
       "  '2016-09-05T19:21:04Z',\n",
       "  '2016-09-05T19:21:16Z',\n",
       "  '2016-09-05T19:57:55Z',\n",
       "  '2016-09-05T21:01:07Z',\n",
       "  '2016-09-05T21:24:09Z',\n",
       "  '2016-09-06T12:13:16Z',\n",
       "  '2016-09-06T12:56:53Z',\n",
       "  '2016-09-06T13:04:51Z',\n",
       "  '2016-09-06T13:12:39Z',\n",
       "  '2016-09-06T13:20:26Z',\n",
       "  '2016-09-06T14:28:19Z',\n",
       "  '2016-09-06T15:06:04Z',\n",
       "  '2016-09-06T15:15:05Z',\n",
       "  '2016-09-08T08:02:15Z',\n",
       "  '2016-09-08T09:45:57Z',\n",
       "  '2016-09-08T09:56:05Z',\n",
       "  '2016-09-08T12:13:29Z',\n",
       "  '2016-09-08T12:16:40Z',\n",
       "  '2016-09-08T16:11:44Z',\n",
       "  '2016-09-08T16:42:36Z',\n",
       "  '2016-09-09T07:46:45Z',\n",
       "  '2016-09-05T11:53:34Z',\n",
       "  '2016-09-09T12:10:19Z',\n",
       "  '2016-09-09T18:16:42Z',\n",
       "  '2016-09-10T18:46:39Z',\n",
       "  '2016-09-12T06:32:11Z',\n",
       "  '2016-09-12T11:46:59Z',\n",
       "  '2016-09-13T13:26:27Z',\n",
       "  '2016-09-14T06:09:40Z',\n",
       "  '2016-09-14T15:35:29Z',\n",
       "  '2016-09-15T08:07:44Z',\n",
       "  '2016-09-15T08:24:05Z',\n",
       "  '2016-09-15T08:48:42Z',\n",
       "  '2016-09-15T08:57:58Z',\n",
       "  '2016-09-15T09:15:52Z',\n",
       "  '2016-09-15T09:31:28Z',\n",
       "  '2016-09-15T12:42:16Z',\n",
       "  '2016-09-15T16:18:29Z',\n",
       "  '2016-09-16T13:47:44Z',\n",
       "  '2016-09-16T16:06:43Z',\n",
       "  '2016-09-17T09:38:43Z',\n",
       "  '2016-09-19T15:46:27Z',\n",
       "  '2016-09-19T15:53:17Z',\n",
       "  '2016-09-19T16:00:41Z',\n",
       "  '2016-09-19T16:03:54Z',\n",
       "  '2016-09-20T07:34:14Z',\n",
       "  '2016-09-20T10:53:58Z',\n",
       "  '2016-09-20T12:38:29Z',\n",
       "  '2016-09-21T06:21:00Z',\n",
       "  '2016-09-21T12:31:11Z',\n",
       "  '2016-09-22T07:39:40Z',\n",
       "  '2016-09-22T08:44:55Z',\n",
       "  '2016-09-22T08:59:56Z',\n",
       "  '2016-09-22T12:39:16Z',\n",
       "  '2016-09-22T18:26:33Z',\n",
       "  '2016-09-22T20:55:33Z',\n",
       "  '2016-09-22T21:04:05Z',\n",
       "  '2016-09-22T21:10:22Z',\n",
       "  '2016-09-22T21:21:55Z',\n",
       "  '2016-09-23T09:37:06Z',\n",
       "  '2016-09-23T13:37:05Z',\n",
       "  '2016-09-23T14:07:28Z',\n",
       "  '2016-09-23T14:10:24Z',\n",
       "  '2016-09-23T14:12:12Z',\n",
       "  '2016-09-26T09:59:54Z',\n",
       "  '2016-09-26T13:25:11Z',\n",
       "  '2016-09-26T15:37:02Z',\n",
       "  '2016-09-26T18:21:53Z',\n",
       "  '2016-09-26T18:22:54Z',\n",
       "  '2016-09-12T15:00:54Z',\n",
       "  '2016-09-27T08:51:43Z',\n",
       "  '2016-09-27T10:55:12Z',\n",
       "  '2016-09-27T13:49:12Z',\n",
       "  '2016-09-29T06:35:08Z',\n",
       "  '2016-09-29T06:37:31Z',\n",
       "  '2016-09-29T08:58:56Z',\n",
       "  '2016-09-29T11:23:29Z',\n",
       "  '2016-09-29T11:23:30Z',\n",
       "  '2016-09-30T06:43:02Z',\n",
       "  '2016-09-30T07:23:54Z',\n",
       "  '2016-09-30T09:51:15Z',\n",
       "  '2016-09-30T12:39:51Z',\n",
       "  '2016-10-02T15:26:22Z',\n",
       "  '2016-10-02T15:32:30Z',\n",
       "  '2016-10-02T15:35:44Z',\n",
       "  '2016-10-02T15:38:58Z',\n",
       "  '2016-10-02T15:42:48Z',\n",
       "  '2016-10-03T08:58:35Z',\n",
       "  '2016-10-03T13:19:34Z',\n",
       "  '2016-10-03T16:37:39Z',\n",
       "  '2016-10-04T08:40:40Z'],\n",
       " 'updated_at': ['2019-02-01T14:56:34Z',\n",
       "  '2019-01-08T12:17:22Z',\n",
       "  '2019-01-28T10:34:24Z',\n",
       "  '2019-02-01T14:52:58Z',\n",
       "  '2019-01-10T14:29:23Z',\n",
       "  '2019-01-08T12:17:22Z',\n",
       "  '2016-09-29T08:28:40Z',\n",
       "  '2019-01-09T12:42:13Z',\n",
       "  '2019-10-01T07:40:47Z',\n",
       "  '2016-09-23T13:13:16Z',\n",
       "  '2017-03-02T09:12:44Z',\n",
       "  '2019-01-10T14:29:22Z',\n",
       "  '2019-01-08T12:17:22Z',\n",
       "  '2017-08-09T15:22:32Z',\n",
       "  '2019-01-08T15:10:45Z',\n",
       "  '2017-12-29T12:36:12Z',\n",
       "  '2017-12-29T12:36:11Z',\n",
       "  '2016-09-07T09:26:35Z',\n",
       "  '2016-09-12T09:10:33Z',\n",
       "  '2016-11-10T10:33:33Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2019-06-11T07:57:35Z',\n",
       "  '2016-09-09T13:33:22Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2018-06-02T07:41:16Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2017-12-29T12:36:11Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2016-09-20T07:05:08Z',\n",
       "  '2016-10-04T11:02:37Z',\n",
       "  '2016-09-29T08:21:05Z',\n",
       "  '2017-02-23T11:12:48Z',\n",
       "  '2019-03-05T11:17:22Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2017-12-29T12:36:10Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2017-12-12T14:29:28Z',\n",
       "  '2019-01-08T12:17:21Z',\n",
       "  '2019-01-15T10:35:52Z',\n",
       "  '2019-09-20T13:20:26Z',\n",
       "  '2019-08-28T13:18:31Z',\n",
       "  '2016-09-26T13:00:44Z',\n",
       "  '2016-10-17T13:43:13Z',\n",
       "  '2019-01-08T12:17:20Z',\n",
       "  '2019-06-03T07:59:29Z',\n",
       "  '2019-01-08T12:17:20Z',\n",
       "  '2019-01-10T14:23:30Z',\n",
       "  '2019-02-25T08:22:48Z',\n",
       "  '2019-01-08T12:17:20Z',\n",
       "  '2017-12-29T12:36:09Z',\n",
       "  '2017-03-01T09:47:22Z',\n",
       "  '2017-12-29T12:36:09Z',\n",
       "  '2017-12-29T12:36:09Z',\n",
       "  '2017-12-29T12:36:09Z',\n",
       "  '2017-12-29T12:36:09Z',\n",
       "  '2019-01-08T12:17:19Z',\n",
       "  '2019-01-10T14:22:20Z',\n",
       "  '2017-12-29T12:36:08Z',\n",
       "  '2017-12-29T12:36:08Z',\n",
       "  '2016-11-22T09:48:46Z',\n",
       "  '2019-01-08T12:17:19Z',\n",
       "  '2019-06-13T07:27:56Z',\n",
       "  '2016-10-06T15:46:05Z',\n",
       "  '2017-12-29T12:36:08Z',\n",
       "  '2017-12-29T12:36:08Z',\n",
       "  '2019-01-14T14:53:40Z',\n",
       "  '2019-01-08T12:17:19Z',\n",
       "  '2016-09-23T10:02:49Z',\n",
       "  '2018-01-16T11:31:01Z',\n",
       "  '2017-12-29T12:36:07Z',\n",
       "  '2018-07-15T07:41:34Z',\n",
       "  '2018-01-25T15:09:36Z',\n",
       "  '2016-09-29T10:02:51Z',\n",
       "  '2017-06-29T10:16:12Z',\n",
       "  '2017-10-18T20:41:30Z',\n",
       "  '2018-03-08T17:53:37Z',\n",
       "  '2019-01-10T13:01:52Z',\n",
       "  '2019-06-11T17:06:08Z',\n",
       "  '2017-02-13T11:32:16Z',\n",
       "  '2019-01-08T12:17:18Z',\n",
       "  '2018-05-08T10:50:39Z',\n",
       "  '2017-07-06T08:23:43Z',\n",
       "  '2016-11-28T06:47:51Z',\n",
       "  '2019-01-08T12:17:18Z',\n",
       "  '2016-12-06T13:08:17Z',\n",
       "  '2019-01-08T12:17:18Z',\n",
       "  '2019-01-10T14:22:20Z',\n",
       "  '2017-12-29T12:36:06Z',\n",
       "  '2019-01-08T12:17:18Z',\n",
       "  '2019-01-08T12:17:18Z',\n",
       "  '2017-12-29T12:36:06Z',\n",
       "  '2017-12-29T12:36:06Z',\n",
       "  '2019-01-08T12:17:18Z',\n",
       "  '2019-02-25T08:29:18Z',\n",
       "  '2017-03-14T08:44:50Z',\n",
       "  '2017-12-29T12:36:05Z',\n",
       "  '2019-01-08T12:17:18Z',\n",
       "  '2017-08-28T11:12:38Z',\n",
       "  '2019-01-08T12:17:17Z']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_candidate_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = create_df(df_dict_candidate_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_use['id'][(df_use['Inplannen 1e gesorek'].notnull())]\n",
    "b = df_use['id'][(df_use['Inplannen 1e gesorek'].notnull()==True)]\n",
    "#df_dict_candidate_act['id'][df_dict_candidate_act['Inplannen 1e gesorek'].isnull()]\n",
    "#df_dict_candidate_act['To schedule'][(df_dict_candidate_act['Inplannen 1e gesorek'].isnull()==False)]\n",
    "#df['To schedule'][(df['Inplannen 1e gesorek'].isnull()==False) & (df['To schedule'].isnull()==True)]=df['Inplannen 1e gesorek'][(df['Inplannen 1e gesorek'].isnull()==False) & (df['To schedule'].isnull()==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = transform_df(df_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df_dict_candidate_act['Inplannen 1e gesorek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = [1,2,3,4,5]\n",
    "a = []\n",
    "if a:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'a'\n",
    "if a:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use = db_to_df(pw='maartens1991', db_name=\"candidates2\", user='root', host='127.0.0.1', port='', database='recruitment_dashboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_to_use = {}\n",
    "for key in key_list:\n",
    "    df_dict_to_use[key]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers={'Authorization': 'Bearer 229aa3876e4fc4447460a13da7f57d1be4111202e1d56d4d0231fb932c1e7cd1'}\n",
    "url = 'https://jdriven.workable.com/spi/v3/'\n",
    "get_cand_data(df_dict_to_use, key_list, url, headers, cand_id_list=None, start_id='', start_date='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 'hello'\n",
    "x = False\n",
    "if b == 'hello' and not x:\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_activities(url, headers, cand_id_list):\n",
    "    '''\n",
    "    Function to create candidate activity dictionary\n",
    "    Inputs:\n",
    "    \n",
    "    df_dict: dictionary containing candidate data\n",
    "    Outputs:\n",
    "    \n",
    "    DataFrame containing the same candidate data as the input\n",
    "    '''\n",
    "    # Create DataFrame column labels\n",
    "    df_dict_cand = {}\n",
    "    key_list_cand = ['id','tags']\n",
    "    stage_name_list = [\n",
    "        'Sourced',\n",
    "        'Applied',\n",
    "        'Shortlisted',\n",
    "        'Talentpool',\n",
    "        'Review',\n",
    "        'To schedule',\n",
    "        'Inplannen 1e gesorek', #not in use anymore --> combine with 'To Schedule' --> delete\n",
    "        'Inplannen 1e gesprek', #not in use anymore --> combine with 'To Schedule' --> delete\n",
    "        'inplannen 2e gesprek', #not in use anymore --> combine with '1st Interview' --> delete\n",
    "        '1st Interview',\n",
    "        '1e gesprek', #not in use anymore --> combine with '1st Interview' --> delete\n",
    "        'Interview 1', #not in use anymore --> combine with '1st Interview' --> delete\n",
    "        '2nd Interview', \n",
    "        'Interview 2', #not in use anymore --> combine with '2nd Interview' --> delete\n",
    "        'Assessment', #not in use anymore --> combine with '2nd Interview' --> delete\n",
    "        '2e gesprek', #not in use anymore --> combine with '2nd Interview' --> delete\n",
    "        'Offer',\n",
    "        'Aanbieding', #not in use anymore --> combine with 'Offer' --> delete\n",
    "        'Hired',\n",
    "        'Aangenomen', #not in use anymore --> combine with 'Hired' --> delete\n",
    "        'Test Fase', #not in use anymore --> delete\n",
    "        'intern evalueren', #not in use anymore --> delete\n",
    "        'Plan 1', #not in use anymore --> delete\n",
    "        'Plan 2', #not in use anymore --> delete\n",
    "        'Vergaarbak' #not in use anymore --> delete\n",
    "    ]\n",
    "\n",
    "    #Add labels to dictionary\n",
    "    for key in key_list_cand:\n",
    "        df_dict_cand[key]=[]    \n",
    "    for key in stage_name_list:\n",
    "        df_dict_cand[key]=[]\n",
    "    df_dict_cand['disqualified_at']=[]\n",
    "\n",
    "    #Retrieve data through API\n",
    "    section = 'candidates/'\n",
    "\n",
    "    for cand_id in cand_id_list:\n",
    "        r_cand_id = requests.get(url+section+cand_id+'.json', headers=headers)\n",
    "        time.sleep(1.0)\n",
    "        for k in key_list_cand:\n",
    "            loc = locate_element(r_cand_id.json()['candidate'],k)\n",
    "            v = r_cand_id.json()['candidate']\n",
    "            for i in loc:\n",
    "                v = v[i]\n",
    "            df_dict_cand[k].append(v)\n",
    "\n",
    "        # loop through activities for candidate cand_id\n",
    "        r_cand_id_act = requests.get(url+section+cand_id+'/activities'+'.json', headers=headers)\n",
    "        r_cand_id_act=r_cand_id_act.json()['activities']\n",
    "        time.sleep(1.0)\n",
    "        stages = deepcopy(stage_name_list)\n",
    "        disqualified=False\n",
    "        for act in r_cand_id_act:\n",
    "            if act['action']=='disqualified' and not disqualified:\n",
    "                df_dict_cand['disqualified_at'].append(act['created_at'])\n",
    "                disqualified=True\n",
    "            if act['stage_name'] in stage_name_list:\n",
    "                if act['stage_name'] not in stages:\n",
    "                    continue\n",
    "                else:\n",
    "                    df_dict_cand[act['stage_name']].append(act['created_at'])\n",
    "                    stages.remove(act['stage_name'])\n",
    "        if disqualified==False:\n",
    "            df_dict_cand['disqualified_at'].append(np.nan)\n",
    "        for remaining_stage in stages:\n",
    "            df_dict_cand[remaining_stage].append(np.nan)         \n",
    "        time.sleep(0.5)\n",
    "    return df_dict_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(dictionary):\n",
    "    '''\n",
    "    Convert dictionary into pandas DataFrame\n",
    "    Inputs:\n",
    "    \n",
    "    df_dict: dictionary containing candidate data\n",
    "    Outputs:\n",
    "    \n",
    "    DataFrame containing the same candidate data as the input\n",
    "    '''\n",
    "    df = pd.DataFrame.from_dict(dictionary, orient='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df1, df2, how='left', on=['id']):\n",
    "    '''\n",
    "    Function to create candidate activity dictionary\n",
    "    Inputs:\n",
    "    \n",
    "    df_dict: dictionary containing candidate data\n",
    "    Outputs:\n",
    "    \n",
    "    DataFrame containing the same candidate data as the input\n",
    "    '''    \n",
    "    df = pd.merge(df1, df2, how=how, on=on)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    '''\n",
    "    Function to transform DataFrame\n",
    "    Inputs:\n",
    "    \n",
    "    df_dict: dictionary containing candidate data\n",
    "    Outputs:\n",
    "    \n",
    "    '''\n",
    "    #Rename duplicate column name to prevent error when creating SQL database\n",
    "    df=df.rename(columns = {'sourced':'is_sourced'})\n",
    "    \n",
    "    #Replace and Delete columns\n",
    "    df['To schedule'][(df['Inplannen 1e gesorek'].notnull()) & (df['To schedule'].isnull())]=df['Inplannen 1e gesorek'][(df['Inplannen 1e gesorek'].notnull()) & (df['To schedule'].isnull())]\n",
    "    df.drop('Inplannen 1e gesorek',axis=1,inplace = True)\n",
    "    df['To schedule'][(df['Inplannen 1e gesprek'].notnull()) & (df['To schedule'].isnull())]=df['Inplannen 1e gesprek'][(df['Inplannen 1e gesprek'].notnull()) & (df['To schedule'].isnull())]\n",
    "    df.drop('Inplannen 1e gesprek',axis=1,inplace = True)\n",
    "    df['1st Interview'][(df['inplannen 2e gesprek'].notnull()) & (df['1st Interview'].isnull())]=df['inplannen 2e gesprek'][(df['inplannen 2e gesprek'].notnull()) & (df['1st Interview'].isnull())]\n",
    "    df.drop('inplannen 2e gesprek',axis=1,inplace = True)\n",
    "    df['1st Interview'][(df['1e gesprek'].notnull()) & (df['1st Interview'].isnull())]=df['1e gesprek'][(df['1e gesprek'].notnull()) & (df['1st Interview'].isnull())]\n",
    "    df.drop('1e gesprek',axis=1,inplace = True)\n",
    "    df['1st Interview'][(df['Interview 1'].notnull()) & (df['1st Interview'].isnull())]=df['Interview 1'][(df['Interview 1'].notnull()) & (df['1st Interview'].isnull())]\n",
    "    df.drop('Interview 1',axis=1,inplace = True)\n",
    "    df['2nd Interview'][(df['Interview 2'].notnull()) & (df['2nd Interview'].isnull())]=df['Interview 2'][(df['Interview 2'].notnull()) & (df['2nd Interview'].isnull())]\n",
    "    df.drop('Interview 2',axis=1,inplace = True)\n",
    "    df['2nd Interview'][(df['Assessment'].notnull()) & (df['2nd Interview'].isnull())]=df['Assessment'][(df['Assessment'].notnull()) & (df['2nd Interview'].isnull())]\n",
    "    df.drop('Assessment',axis=1,inplace = True)\n",
    "    df['2nd Interview'][(df['2e gesprek'].notnull()) & (df['2nd Interview'].isnull())]=df['2e gesprek'][(df['2e gesprek'].notnull()) & (df['2nd Interview'].isnull())]\n",
    "    df.drop('2e gesprek',axis=1,inplace = True)\n",
    "    df['Offer'][(df['Aanbieding'].notnull()) & (df['Offer'].isnull())]=df['Aanbieding'][(df['Aanbieding'].notnull()) & (df['Offer'].isnull())]\n",
    "    df.drop('Aanbieding',axis=1,inplace = True)\n",
    "\n",
    "    df['Hired'][(df['Aangenomen'].notnull()) & (df['Hired'].isnull())]=df['Aangenomen'][(df['Aangenomen'].notnull()) & (df['Hired'].isnull())]\n",
    "    df.drop('Aangenomen',axis=1,inplace = True)\n",
    "\n",
    "    # Delete Columns\n",
    "    df.drop('Test Fase',axis=1,inplace = True)\n",
    "    df.drop('intern evalueren',axis=1,inplace = True)\n",
    "    df.drop('Plan 1',axis=1,inplace = True)\n",
    "    df.drop('Plan 2',axis=1,inplace = True)\n",
    "    df.drop('Vergaarbak',axis=1,inplace = True)\n",
    "\n",
    "    #Remove only for now (will be used for source of candidate)\n",
    "    df.drop('tags',axis=1,inplace = True)\n",
    "\n",
    "    #Replace np.nan with None, as None is accepted if df is written to a DB using df.to_sql\n",
    "    #Note that None will only be converted to NULL in SQL if df.to_sql is used, not using executemany\n",
    "    #NaT is converted as None if using to_sql\n",
    "    df = df.where((pd.notnull(df)), None)\n",
    "\n",
    "    #Convert None to 'nan' if getting errors when inserting into MySQL DB\n",
    "    #df.fillna(value='nan', inplace=True)\n",
    "\n",
    "    #Convert date columns into DATE columns with specified format\n",
    "    date_cols = [\n",
    "            'hired_at',\n",
    "            'Sourced',\n",
    "            'Applied',\n",
    "            'Shortlisted',\n",
    "            'Talentpool',\n",
    "            'Review',\n",
    "            'To schedule',\n",
    "            '1st Interview',\n",
    "            '2nd Interview',\n",
    "            'Offer',\n",
    "            'Hired',\n",
    "            'disqualified_at'\n",
    "    ]\n",
    "    for date_col in date_cols:\n",
    "        df[date_col]=pd.to_datetime(pd.to_datetime(df[date_col]).dt.strftime('%Y-%m-%d'))\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col]=df[col].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "            df[col][df[col].notnull()]=df[col][df[col].notnull()].apply(lambda x: x.lower())    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = db_to_df(pw='maartens1991',db_name=\"candidates2\",user='root',host='127.0.0.1',port='',database='recruitment_dashboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = transform_df(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_db(df, pw, db_name='candidates', user='root:', host='localhost', port='', schema='recruitment_dashboard'):\n",
    "    '''\n",
    "    Function to write DataFrame to MySQL DB\n",
    "    Inputs:\n",
    "    df: DataFrame containing all candidate data\n",
    "    db_name: Name of the to be created MySQL DB (default is 'candidates2')\n",
    "    user: user name of db (default is 'root')\n",
    "    pw: password of database\n",
    "    host = 'localhost' if connecting to local DB\n",
    "    host = '<IP address of DB>' if connecting to a DB hosted externally\n",
    "    port: port (default is no port specified). Format is: ':<port>'\n",
    "    schema: database schema name\n",
    "    \n",
    "    Outputs:\n",
    "    Populated MySQL Database\n",
    "    '''\n",
    "    engine = create_engine('mysql+pymysql://'+user+pw+'@'+host+port+'/'+schema, echo = False)\n",
    "    df.to_sql(name = db_name, con = engine, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = db_to_df(pw='maartens1991',db_name=\"candidates2\",user='root',host='127.0.0.1',port='',database='recruitment_dashboard')\n",
    "df_to_db(df=df_db, pw='maartens1991', db_name='test', user='root:', host='localhost', port='', schema='recruitment_dashboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_to_df(pw, db_name=\"candidates\", user='root', host='127.0.0.1', port='', database='recruitment_dashboard'):\n",
    "    '''\n",
    "    Function to convert MySQL DB to DataFrame\n",
    "    Inputs:\n",
    "    db_name: Name of the to be created MySQL DB (default is 'candidates2')\n",
    "    user: user name of db (default is 'root')\n",
    "    pw: password of database\n",
    "    host = '127.0.0.1' if connecting to local DB\n",
    "    host = '<IP address of DB>' if connecting to a DB hosted externally\n",
    "    port: port (default is no port specified). Format is: ':<port>'\n",
    "    database: database schema name\n",
    "    \n",
    "    Outputs:\n",
    "    Populated MySQL Database\n",
    "    '''\n",
    "    conn = mysql.connector.connect(user=user, password=pw,host=host, database=database)\n",
    "    df = pd.read_sql(\"SELECT * from \"+db_name, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_funnel(df, start_year=2014, start_month=1, start_day=1, end_year=2017, end_month=1, end_day=1):\n",
    "    '''\n",
    "    Function to retrieve interview process funnel for specified time frame\n",
    "    Inputs:\n",
    "    df: DataFrame containing info about all candidates\n",
    "    start_date\n",
    "    end_date\n",
    "\n",
    "    \n",
    "    Outputs:\n",
    "    funnel_dict: dictionary containing the number of candidates in each funnel stage for specified time frame\n",
    "    '''\n",
    "    start_date = datetime.datetime(start_year, start_month, start_day)\n",
    "    end_date = datetime.datetime(end_year, end_month, end_day)\n",
    "\n",
    "    funnel_stages = [\n",
    "            'Sourced',\n",
    "            'Applied',\n",
    "            'Shortlisted',\n",
    "            'Talentpool',\n",
    "            'Review',\n",
    "            'To schedule',\n",
    "            '1st Interview',\n",
    "            '2nd Interview',\n",
    "            'Offer',\n",
    "            'Hired',\n",
    "            'disqualified_at'\n",
    "    ]\n",
    "    funnel_dict={}\n",
    "    for funnel in funnel_stages:\n",
    "        funnel_dict[funnel]=df[funnel][(df[funnel]>start_date) & (df[funnel]<=end_date)].count()\n",
    "    return funnel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_funnel(pw, db_name=\"candidates\", user='root', host='127.0.0.1', port='', database='recruitment_dashboard', start_year=2014, start_month=1, start_day=1, end_year=2017, end_month=1, end_day=1):\n",
    "    df = db_to_df(pw, db_name, user, host, port, database)\n",
    "    funnel_dict=retrieve_funnel(df,start_year, start_month, start_day, end_year, end_month, end_day)\n",
    "    plt.figure(figsize=(12, 12), dpi=80) # figsize=(width,height)\n",
    "    plt.bar(range(len(funnel_dict)), list(funnel_dict.values()), align='center')\n",
    "    plt.xticks(range(len(funnel_dict)), list(funnel_dict.keys()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db(pw, url, headers, key_list, db_name=\"candidates\", user='root', host='127.0.0.1', port='', database='recruitment_dashboard', start_date=''):\n",
    "    first_api_id = requests.get(url+'candidates'+'.json', headers=headers).json()['candidates'][0]['id']\n",
    "    # Create empty df_dict\n",
    "    df_dict={}\n",
    "    for key in key_list:\n",
    "        df_dict[key]=[]\n",
    "    df_dict, since_id, cand_id_list = get_cand_data(df_dict, key_list, url, headers, cand_id_list=[], start_id=first_api_id, start_date=start_date)\n",
    "    while since_id!=None:\n",
    "        df_dict, since_id, cand_id_list = get_cand_data(df_dict, key_list, url, headers, cand_id_list=cand_id_list, start_id=since_id, start_date=start_date)\n",
    "        time.sleep(2.0) \n",
    "    if cand_id_list!=[]:\n",
    "        df_dict_cand=retrieve_activities(url,headers,cand_id_list)\n",
    "        df_cand=create_df(df_dict)\n",
    "        df_act=create_df(df_dict_cand)\n",
    "        df_comb=merge_df(df_cand,df_act,how='left', on=['id'])\n",
    "        df_comb=transform_df(df_comb)\n",
    "        df_to_db(df_comb,pw,db_name,user+':',host,port,schema=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db(pw, url, headers, key_list, db_name=\"candidates\", user='root', host='127.0.0.1', port='', database='recruitment_dashboard',start_date=''):    \n",
    "    last_db_id = retrieve_last_db_entry(pw, db_name, user, host, port, database)\n",
    "    # Create empty df_dict\n",
    "    df_dict={}\n",
    "    for key in key_list:\n",
    "        df_dict[key]=[]\n",
    "    df_dict, since_id, cand_id_list = get_cand_data(df_dict, key_list, url, headers, cand_id_list=[], start_id=last_db_id, start_date=start_date)\n",
    "    while since_id!=None:\n",
    "        df_dict, since_id, cand_id_list = get_cand_data(df_dict, url, headers, cand_id_list=cand_id_list, start_id=since_id, start_date=start_date)\n",
    "        time.sleep(2.0)\n",
    "    #Remove first item in cand_id_list to avoid duplicate of the last_db_id\n",
    "    cand_id_list.remove(last_db_id)\n",
    "    #Remove first item in all the keys in df_dict to avoid duplicate of the last_db_id\n",
    "    for key in df_dict.keys():\n",
    "        df_dict[key].pop(0)\n",
    "    if cand_id_list!=[]:\n",
    "        df_dict_cand=retrieve_activities(url,headers,cand_id_list)\n",
    "        df_cand=create_df(df_dict)\n",
    "        df_act=create_df(df_dict_cand)\n",
    "        df_comb=merge_df(df_cand,df_act,how='left', on=['id'])\n",
    "        df_comb=transform_df(df_comb)\n",
    "        df_to_db(df_comb,pw,db_name,user+':',host,port,schema=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_api_entry(url,headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_db(pw='maartens1991',db_name=\"candidates2\",user='root',host='127.0.0.1',port='',database='recruitment_dashboard',start_date='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.relativedelta\n",
    "\n",
    "def retrieve_funnel_L4M(df):\n",
    "    '''\n",
    "    Function to retrieve interview process funnel for specified time frame\n",
    "    Inputs:\n",
    "    df: DataFrame containing info about all candidates\n",
    "    start_date\n",
    "    end_date\n",
    "\n",
    "    \n",
    "    Outputs:\n",
    "    funnel_dict: dictionary containing the number of candidates in each funnel stage for specified time frame\n",
    "    '''\n",
    "    funnel_stages = [\n",
    "            #'Sourced',\n",
    "            #'Applied',\n",
    "            #'Shortlisted',\n",
    "            #'Talentpool',\n",
    "            'Review',\n",
    "            #'To schedule',\n",
    "            '1st Interview',\n",
    "            '2nd Interview',\n",
    "            #'Offer',\n",
    "            'Hired',\n",
    "            #'disqualified_at'\n",
    "    ]\n",
    "\n",
    "    #Create empty funnel_dict containing all funnel stages\n",
    "    funnel_dict={}\n",
    "    for funnel in funnel_stages:\n",
    "        funnel_dict[funnel]=[]\n",
    "    \n",
    "    #Populate funnel_dict\n",
    "    periods = [1,2,3,4]\n",
    "    for funnel in funnel_stages:\n",
    "        for period in reversed(periods):\n",
    "            end_date = datetime.datetime.today() - dateutil.relativedelta.relativedelta(months=(1*period)-1)\n",
    "            start_date = datetime.datetime.today() - dateutil.relativedelta.relativedelta(months=1*period)\n",
    "            funnel_dict[funnel].append(df[funnel][(df[funnel]>start_date) & (df[funnel]<=end_date)].count())\n",
    "    return funnel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_funnel_L4M(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieve_funnel(df_db,start_year=2019, start_month=8, start_day=7, end_year=2019, end_month=9, end_day=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime.today() - dateutil.relativedelta.relativedelta(months=1)\n",
    "end_date = datetime.datetime.today() - dateutil.relativedelta.relativedelta(months=0)\n",
    "df_db['name'][(df_db['2nd Interview']>start_date) & (df_db['2nd Interview']<=end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Get data\n",
    "funnel_dict = retrieve_funnel_L4M(df_db)\n",
    "\n",
    "labels = ['M-3', 'M-2', 'M-1', 'M0']\n",
    "review = funnel_dict['Review']\n",
    "first_interview = funnel_dict['1st Interview']\n",
    "second_interview = funnel_dict['2nd Interview']\n",
    "hired = funnel_dict['Hired']\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14,8))\n",
    "#figure(figsize=(18, 10), dpi=80) # figsize=(width,height)\n",
    "rects1 = ax.bar(x - 1.5*width, review, width, color=plt.cm.tab20c(0), label='Reviews')\n",
    "rects2 = ax.bar(x - 1/2*width, first_interview, width, color=plt.cm.tab20c(1),label='Succesful Reviews')\n",
    "rects3 = ax.bar(x + 1/2*width, second_interview, width, color=plt.cm.tab20c(2),label='Succesful 1st Interviews')\n",
    "rects4 = ax.bar(x + 1.5*width, hired, width, color=plt.cm.tab20c(3),label='Succesful 2nd Interviews')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('# Candidates',fontweight='bold')\n",
    "ax.set_title('Recruitment Funnel: #Candidates by Month and Funnel Stage')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xlabel('Month', fontweight='bold')\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_funnel(pw='maartens1991',db_name=\"candidates2\",user='root',host='127.0.0.1',port='',database='recruitment_dashboard',start_year=2019, start_month=7, start_day=6, end_year=2019, end_month=10, end_day=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if a:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to Google Cloud DB\n",
    "engine_cloud = create_engine('mysql+pymysql://root:MjB6KtDfI4pkzKr9@34.90.224.97/recruitment', echo = False)\n",
    "df_comb.to_sql(name = 'candidates2', con = engine_cloud, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local DB\n",
    "\n",
    "try:\n",
    "    conn = mysql.connector.connect(user='root', password='maartens1991',host='127.0.0.1', database='recruitment_dashboard')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create table REPLACE WITH CODE BELOW TO MAKE QUERY STATEMENT AND THEN EXECUTE\n",
    "    # Create sql_create_table_query = ... columns and data type\n",
    "    col_dtype = []\n",
    "    for col in df_comb.columns.tolist():\n",
    "        col_dtype.append(col+' '+str(df_comb[col].dtype))\n",
    "    \n",
    "    #Replace objects with TEXT as object is not a data type that can be parsed into CREATE TABLE statement\n",
    "    #Remove spaces in column name, replace with underscore\n",
    "    #Rename sourced to is_sourced\n",
    "    col_dtype = [s.replace('sourced', 'is_sourced') for s in col_dtype]\n",
    "    col_dtype = [s.replace('To schedule', 'To_schedule') for s in col_dtype]\n",
    "    col_dtype = [s.replace('1st Interview', '1st_Interview') for s in col_dtype]\n",
    "    col_dtype = [s.replace('2nd Interview', '2nd_Interview') for s in col_dtype]\n",
    "    col_dtype = [s.replace('object', 'TEXT') for s in col_dtype]\n",
    "    col_dtype = [s.replace('<M8[ns]', 'DATE') for s in col_dtype]\n",
    "    #if column data type is DATE, then dates have to be in the following format (as a string): YYYY-MM-DD\n",
    "    # All values in column have to be in this format, it does not take a string like 'nan'\n",
    "    # MySQL does accept NULL (not as a string, just as NULL)\n",
    "    table_col = ','.join(col_dtype)\n",
    "    \n",
    "    sql_create_table_query = \"\"\"CREATE TABLE candidates (%s)\"\"\"%(table_col)\n",
    "    cursor.execute(sql_create_table_query)\n",
    "    \n",
    "    # Save (commit) the changes\n",
    "    conn.commit()\n",
    "\n",
    "    # Select column names in order from 1st to last column\n",
    "    sql_select_query = '''SELECT column_name\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'recruitment_dashboard'\n",
    "    AND table_name   = 'candidates'\n",
    "    ORDER BY ORDINAL_POSITION\n",
    "    '''\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql_select_query)\n",
    "    records = cursor.fetchall() \n",
    "    columns = []\n",
    "    for i in records:\n",
    "        columns.append(i[0])\n",
    "    col_n = ','.join(columns)\n",
    "\n",
    "    #Records to insert in SQL table\n",
    "    records_to_insert = list(df_comb.itertuples(index=False, name=None))\n",
    "    params = ['%s' for item in records_to_insert[0]] # always use '%s' no matter the data type of the column\n",
    "    var_string = ','.join(params)\n",
    "\n",
    "    #Insert all records into table\n",
    "    sql_insert_query = \"\"\"INSERT INTO candidates (%s) VALUES (%s);\"\"\" %(col_n,var_string)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.executemany(sql_insert_query, records_to_insert)\n",
    "    \n",
    "    #Commit all changes\n",
    "    conn.commit()\n",
    "\n",
    "except (Exception, mysql.connector.Error) as error:\n",
    "    print (\"Error while connecting to SQL DB\", error)\n",
    "finally:\n",
    "    #Closing database connection\n",
    "    if(conn):\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"SQL DB connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Database\n",
    "\n",
    "try:\n",
    "    conn = mysql.connector.connect(user='root', password='MjB6KtDfI4pkzKr9',host='34.90.224.97', database='recruitment')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create table REPLACE WITH CODE BELOW TO MAKE QUERY STATEMENT AND THEN EXECUTE\n",
    "    # Create sql_create_table_query = ... columns and data type\n",
    "    col_dtype = []\n",
    "    for col in df_comb.columns.tolist():\n",
    "        col_dtype.append(col+' '+str(df_comb[col].dtype))\n",
    "    \n",
    "    #Replace objects with TEXT as object is not a data type that can be parsed into CREATE TABLE statement\n",
    "    #Remove spaces in column name, replace with underscore\n",
    "    #Rename sourced to is_sourced\n",
    "    col_dtype = [s.replace('sourced', 'is_sourced') for s in col_dtype]\n",
    "    col_dtype = [s.replace('To schedule', 'To_schedule') for s in col_dtype]\n",
    "    col_dtype = [s.replace('1st Interview', '1st_Interview') for s in col_dtype]\n",
    "    col_dtype = [s.replace('2nd Interview', '2nd_Interview') for s in col_dtype]\n",
    "    col_dtype = [s.replace('object', 'TEXT') for s in col_dtype]\n",
    "    table_col = ','.join(col_dtype)\n",
    "    \n",
    "    sql_create_table_query = \"\"\"CREATE TABLE candidates (%s)\"\"\"%(table_col)\n",
    "    cursor.execute(sql_create_table_query)\n",
    "    \n",
    "    # Save (commit) the changes\n",
    "    conn.commit()\n",
    "\n",
    "    # Select column names in order from 1st to last column\n",
    "    sql_select_query = '''SELECT column_name\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'recruitment_dashboard'\n",
    "    AND table_name   = 'candidates'\n",
    "    ORDER BY ORDINAL_POSITION\n",
    "    '''\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql_select_query)\n",
    "    records = cursor.fetchall() \n",
    "    columns = []\n",
    "    for i in records:\n",
    "        columns.append(i[0])\n",
    "    col_n = ','.join(columns)\n",
    "\n",
    "    #Records to insert in SQL table\n",
    "    records_to_insert = list(df_comb.itertuples(index=False, name=None))\n",
    "    params = ['%s' for item in records_to_insert[0]] # always use '%s' no matter the data type of the column\n",
    "    var_string = ','.join(params)\n",
    "\n",
    "    #Insert all records into table\n",
    "    sql_insert_query = \"\"\"INSERT INTO candidates (%s) VALUES (%s);\"\"\" %(col_n,var_string)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.executemany(sql_insert_query, records_to_insert)\n",
    "    \n",
    "    #Commit all changes\n",
    "    conn.commit()\n",
    "\n",
    "except (Exception, mysql.connector.Error) as error:\n",
    "    print (\"Error while connecting to SQL DB\", error)\n",
    "finally:\n",
    "    #Closing database connection\n",
    "    if(conn):\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"SQL DB connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(url+'candidates'+'.json', headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidate': {'id': '491fdff',\n",
       "  'name': 'Niels Theunissen',\n",
       "  'firstname': 'Niels',\n",
       "  'lastname': 'Theunissen',\n",
       "  'headline': None,\n",
       "  'image_url': 'https://dvz3vrza543jw.cloudfront.net/uploads/137223/329280/76675373/image/805e79c2-228b-43c8-9250-eb7dcbbd550b.png',\n",
       "  'account': {'subdomain': 'jdriven',\n",
       "   'name': 'JDriven/JCore/BigData Republic'},\n",
       "  'job': {'shortcode': 'A8C5321F60', 'title': 'Big Data Scientist (BDR)'},\n",
       "  'stage': 'Review',\n",
       "  'disqualified': False,\n",
       "  'disqualified_at': None,\n",
       "  'disqualification_reason': None,\n",
       "  'hired_at': None,\n",
       "  'sourced': True,\n",
       "  'profile_url': 'https://jdriven.workable.com/backend/jobs/329280/candidates/76675373',\n",
       "  'address': None,\n",
       "  'phone': '(+31) (0)6 41 97 97 98',\n",
       "  'email': 'n.p.theunissen@gmail.com',\n",
       "  'outbound_mailbox': '4f38l2iro2h1@outbound.workablemail.com',\n",
       "  'domain': 'Wenham International',\n",
       "  'uploader_id': 'a132a',\n",
       "  'created_at': '2019-10-07T07:55:02Z',\n",
       "  'updated_at': '2019-10-10T12:27:41Z',\n",
       "  'cover_letter': None,\n",
       "  'summary': None,\n",
       "  'education_entries': [],\n",
       "  'experience_entries': [],\n",
       "  'skills': [],\n",
       "  'answers': [],\n",
       "  'resume_url': 'https://workablehr.s3.amazonaws.com/uploads/137223/329280/76675373/download/CURRICULUM_VITAE_Niels_Theunissen_sept_2019__1_.pdf?X-Amz-Expires=60000&X-Amz-Date=20191010T144304Z&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIR2MIE33PRKXR4CA%2F20191010%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Signature=8417913b150b1cd1c3b6f3030afeeed724198d340e7bff104f5358fd9001ac7d',\n",
       "  'social_profiles': [{'type': 'gravatar',\n",
       "    'name': 'Gravatar',\n",
       "    'username': 'nielstheun',\n",
       "    'url': 'http://en.gravatar.com/nielstheun'}],\n",
       "  'tags': ['week41_2019', 'wenham_carter_internation']}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers={'Authorization': 'Bearer 229aa3876e4fc4447460a13da7f57d1be4111202e1d56d4d0231fb932c1e7cd1'}\n",
    "url = 'https://jdriven.workable.com/spi/v3/'\n",
    "requests.get(url+'candidates/491fdff'+'.json', headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url+'candidates/422cf23'+'.json', headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Fri, 11 Oct 2019 09:07:02 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Set-Cookie': '__cfduid=d143244c36b73a110797ed4a709d35c8c1570784822; expires=Sat, 10-Oct-20 09:07:02 GMT; path=/; domain=.workable.com; HttpOnly; Secure', 'x-frame-options': 'SAMEORIGIN', 'x-xss-protection': '1; mode=block', 'x-content-type-options': 'nosniff', 'x-download-options': 'noopen', 'x-permitted-cross-domain-policies': 'none', 'referrer-policy': 'strict-origin-when-cross-origin', 'vary': 'User-Agent', 'x-rate-limit-limit': '10', 'x-rate-limit-remaining': '9', 'x-rate-limit-reset': '1570784832', 'etag': 'W/\"5bd2828f0b8d8cf03011cbcedb214264\"', 'cache-control': 'max-age=0, private, must-revalidate', 'x-request-id': 'f0c81113-8665-4865-a01b-f424891e723e', 'x-runtime': '0.067653', 'x-envoy-upstream-service-time': '72', 'CF-Cache-Status': 'DYNAMIC', 'Strict-Transport-Security': 'max-age=15552000; includeSubDomains', 'Expect-CT': 'max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"', 'Server': 'cloudflare', 'CF-RAY': '523fae74c8f1c781-AMS', 'Content-Encoding': 'gzip'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['x-rate-limit-limit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = 'candidates?'\n",
    "start_date = '2010-01-01T10:10:10Z'\n",
    "r_cand = requests.get(url+section+'limit=100&created_after='+start_date+'.json', headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cand.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests.get(url+'candidates/48384b3'+'.json', headers=headers).json()\n",
    "#requests.get(url+'candidates/48384b3/activities'+'.json', headers=headers).json()['activities']\n",
    "#section = 'events?'\n",
    "#events = requests.get(url+section+'.json', headers=headers).json()\n",
    "\n",
    "#section = 'jobs/A8C5321F60/activities'\n",
    "#j = requests.get(url+section+'.json', headers=headers).json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
