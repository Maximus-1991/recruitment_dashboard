{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# Check why max_id doesnt work\n",
    "\n",
    "# Check if names have multiple entries\n",
    "# Retrieve all keys in dictionary that do not contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workable API\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "headers={'Authorization': 'Bearer 229aa3876e4fc4447460a13da7f57d1be4111202e1d56d4d0231fb932c1e7cd1'}\n",
    "url = 'https://jdriven.workable.com/spi/v3/'\n",
    "\n",
    "#r_jobs = requests.get(url+'jobs.json', headers=headers)\n",
    "#r_stages = requests.get(url+'stages.json', headers=headers)\n",
    "#r_cand = requests.get(url+'candidates.json', headers=headers)\n",
    "\n",
    "#By default results are limited to 50. The limit can by updated via the request parameter limit\n",
    "#The value specified cannot be more than 100.\n",
    "#cand_dict['paging']\n",
    "#{'next': 'https://jdriven.workable.com/spi/v3/candidates?limit=50&since_id=e48b5d'}\n",
    "\n",
    "#since_id: string. Returns results with an ID greater than or equal to the specified ID\n",
    "\n",
    "#paging indicates what the next webpage is. \n",
    "# Since_id indicates that the requested data is taken before the since_ID\n",
    "# In other words, the next page starts with since_D\n",
    "# {'next': 'https://jdriven.workable.com/spi/v3/candidates?limit=100&since_id=f36d27'}\n",
    "# Limit indicates the number of IDs retrieved before the since_ID\n",
    "\n",
    "#max_id\n",
    "# Get max_id, limit=100 to get the 100 latest entries\n",
    "# Then use the first entry of that request for the following request, using since_Id=first entry of the first request\n",
    "\n",
    "# I want to retrieve the last ID\n",
    "# Maybe can retrieve using created_after and setting this to last week. If it cannot find anything, using another week back in time\n",
    "#'https://jdriven.workable.com/spi/v3/candidates?limit=100&created_after=2019-09-01T13:29:49Z}'\n",
    "\n",
    "#Timestamp parameters input format\n",
    "#Supported input formats for the timestamp fields created_after & updated_after are:\n",
    "#ISO8601 e.g. 20150708T115616Z\n",
    "#Unix time (e.g. 1436356721)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maarten\\Anaconda3\\envs\\ams\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from collections import Sequence\n",
    "from itertools import chain, count, tee\n",
    "\n",
    "def locate_element(data,look_up_elem):\n",
    "    '''\n",
    "    Function to locate the exact location of a an element in a data structure\n",
    "    '''\n",
    "    data_orig = data\n",
    "    loc_list = []\n",
    "    \n",
    "    #### Step 1: Create loop: while look_up_elem not in loc_list\n",
    "    while look_up_elem not in loc_list:\n",
    "\n",
    "        data = data_orig\n",
    "        if loc_list != []:\n",
    "            for location in loc_list:\n",
    "                data = data[location]     \n",
    "        \n",
    "        #### Step 2: Create loop for each element in data. This element needs to be appended to loc_list if element is found in (sub-levels of) this element\n",
    "        # Combine step 4 and 5 in one function. Function is to flatten the data and check if look_up_elem is present in data. If element is found, return loc_list\n",
    "        def check_branche(data):\n",
    "                    #### Step 2: Check if look_up_element is present on 1st level of data\n",
    "            if look_up_elem in data:\n",
    "                loc_list.append(look_up_elem)\n",
    "                return loc_list\n",
    "\n",
    "            #### Step 3: If element not present on 1st level, filter out strings and integers from data. Method is different for different data types\n",
    "            # Note: data_tuple = () (will be problematic, as you cannot append elements to a tuple). We may be able to add items from tuple to list as tuple is also a Sequence\n",
    "\n",
    "            # Define data_elements\n",
    "            if type(data)==dict: \n",
    "                data_elements = list(data.keys())\n",
    "            elif type(data)==list: \n",
    "                data_elements = list(range(len(data)))\n",
    "            # elif type(data)==tuple: \n",
    "                #data_elements = list(range(len(data)))\n",
    "\n",
    "            else:\n",
    "                return \"Element not present\"\n",
    "                      \n",
    "            for element in data_elements:\n",
    "\n",
    "                data_to_check = data[element]\n",
    "\n",
    "                # Define data_dict, data_list and data_tuple\n",
    "                if type(data_to_check)==dict:\n",
    "                    data_dict = data_to_check\n",
    "                    data_list = []\n",
    "                    data_tuple = ()\n",
    "                elif type(data_to_check)==list:\n",
    "                    data_dict = {}\n",
    "                    data_list = data_to_check\n",
    "                    data_tuple = ()\n",
    "                elif type(data_to_check)==tuple:\n",
    "                    data_dict = {}\n",
    "                    data_list = []\n",
    "                    data_tuple = data_to_check\n",
    "                elif type(data_to_check)!=dict and type(data_to_check)!=list and type(data_to_check)!=tuple:\n",
    "                    continue\n",
    "                else:\n",
    "                    return \"Error\"\n",
    "\n",
    "                #### Step 5: Enter while loop (is within the for loop of step 4). From the filtered data obtained in step 3, divide the different elements into its data type. Then, flatten type(data) data type first and then the other two data types\n",
    "                # When look_up_elem is found, append element to loc_list and return loc_list\n",
    "                while data_dict != {} or data_list != [] or data_tuple !=():\n",
    "                    # Flatten dictionary and check if element is present on any of the levels and add list elements to data_list\n",
    "                    # After first round, if any elements were added to data_dict, go through these added elements\n",
    "                    while data_dict != {}:\n",
    "                        if look_up_elem in data_dict:\n",
    "                            loc_list.append(element)\n",
    "                            return \n",
    "                            \n",
    "                        data_dict_temp = {}\n",
    "                        # Filter the elements in data_dict\n",
    "                        for key,value in iter(data_dict.items()):\n",
    "                            if type(value)==dict:\n",
    "                                data_dict_temp.update(value)\n",
    "                            elif type(value)==list:\n",
    "                                data_list.append(value)\n",
    "                            #elif type(value)==tuple:\n",
    "                            #    test_tuple\n",
    "                            # to check if tuple is also a sequence, can also use chain(element) for this\n",
    "                            else:\n",
    "                                \"Element is string or integer\"\n",
    "                        data_dict = data_dict_temp\n",
    "\n",
    "                    # After data_dict is (temporarily) exhausted, go through data_list\n",
    "                    while data_list != []:\n",
    "                        if look_up_elem in data_list:\n",
    "                            loc_list.append(element)\n",
    "                            return loc_list\n",
    "\n",
    "                        data_list_temp = []\n",
    "                        # Filter the elements in data_dict\n",
    "                        for item in data_list:\n",
    "                            if type(item)==dict:\n",
    "                                data_dict.update(item)\n",
    "                            elif type(item)==list:\n",
    "                                for i in item:\n",
    "                                    data_list_temp.append(i)\n",
    "                            else:\n",
    "                                \"Element is string or integer\"\n",
    "                        data_list = data_list_temp\n",
    "\n",
    "                    # After data_list is (temporarily) exhausted, go through data_tuple\n",
    "                    #while data_tuple !=():\n",
    "                        # Flatten tuple, check if element is present on any of the levels and add dictionary and list elements to data_dict or data_list\n",
    "                        #pass\n",
    "\n",
    "            if look_up_elem not in loc_list:\n",
    "                return \"Element not Found\"\n",
    "        check_branche(data)\n",
    "    \n",
    "    return loc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def change_name_duplicate_keys(d):\n",
    "    d_no_dupes = copy.deepcopy(d)\n",
    "    all_keys = {}\n",
    "    all_keys_temp = {}\n",
    "    list_check = []\n",
    "    duplicate_remover_dict = d_no_dupes  \n",
    "    while duplicate_remover_dict !={}:\n",
    "        dict_temp = {}\n",
    "        no_dupes = 0\n",
    "        for key,value in iter(duplicate_remover_dict.items()):\n",
    "            if type(value)==dict and value !={}:\n",
    "                for k,v in value.items():\n",
    "                    if k in dict_temp or k in all_keys: \n",
    "                        key_to_replace = k\n",
    "                        key_loc = locate_element(duplicate_remover_dict,key_to_replace)\n",
    "                        key_new = key_to_replace+'_'+str(key_loc[len(key_loc)-2])\n",
    "                        replacement_dict = duplicate_remover_dict\n",
    "                        for key in key_loc[:len(key_loc)-1]:\n",
    "                            replacement_dict = replacement_dict[key]\n",
    "                        replacement_dict[key_new] = replacement_dict.pop(key_to_replace)\n",
    "                        no_dupes = 1\n",
    "                    else:\n",
    "                        all_keys_temp.update({k:v})\n",
    "                if no_dupes ==1:\n",
    "                    all_keys_temp = {}\n",
    "                    break\n",
    "                else:\n",
    "                    dict_temp.update(value)\n",
    "            \n",
    "            elif type(value)==list and value != []:\n",
    "                if all(type(item) == dict for item in value):\n",
    "                    for item in value:\n",
    "                        for k,v in item.items():\n",
    "                            if k in all_keys or k in dict_temp:\n",
    "                                key_to_replace = k\n",
    "                                key_loc = locate_element(duplicate_remover_dict,key_to_replace)\n",
    "                                key_new = key_to_replace+'_'+str(key_loc[len(key_loc)-2])\n",
    "                                replacement_dict = duplicate_remover_dict\n",
    "                                for key in key_loc[:len(key_loc)-1]:\n",
    "                                    replacement_dict = replacement_dict[key]\n",
    "                                replacement_dict[key_new] = replacement_dict.pop(key_to_replace)\n",
    "                                no_dupes = 1\n",
    "                            else:\n",
    "                                all_keys_temp.update({k:v})\n",
    "                        if no_dupes ==1:\n",
    "                            all_keys_temp = {}\n",
    "                            break\n",
    "                        else:\n",
    "                            dict_temp.update(item)\n",
    "                else:\n",
    "                    all_keys_temp.update({key:value})\n",
    "                    for i in value:\n",
    "                        list_check.append(i)\n",
    "                    # Append any dict in value (list) to dict_temp.update \n",
    "                    while list_check != []:\n",
    "                        list_temp = []\n",
    "                        for item in list_check:\n",
    "                            if type(item)==dict:\n",
    "                                # Check if item not duplicate \n",
    "                                for k,v in item.items():\n",
    "                                    if k in all_keys or k in dict_temp:\n",
    "                                        key_to_replace = k\n",
    "                                        key_loc = locate_element(duplicate_remover_dict,key_to_replace)\n",
    "                                        key_new = key_to_replace+'_'+str(key_loc[len(key_loc)-2])\n",
    "                                        replacement_dict = duplicate_remover_dict\n",
    "                                        for key in key_loc[:len(key_loc)-1]:\n",
    "                                            replacement_dict = replacement_dict[key]\n",
    "                                        replacement_dict[key_new] = replacement_dict.pop(key_to_replace)\n",
    "                                        no_dupes = 1\n",
    "                                    else:\n",
    "                                        all_keys_temp.update({k:v})\n",
    "                                if no_dupes == 1:\n",
    "                                    all_keys_temp = {}\n",
    "                                    break\n",
    "                                else:\n",
    "                                    dict_temp.update(item)\n",
    "                            elif type(item)==list:\n",
    "                                for i in item:\n",
    "                                    list_temp.append(i)\n",
    "                            else:\n",
    "                                continue\n",
    "                        list_check = list_temp\n",
    "                              \n",
    "            else:\n",
    "                if key in all_keys or key in dict_temp: \n",
    "                    key_to_replace = key\n",
    "                    key_loc = locate_element(d_no_dupes,key_to_replace) #You use d_no_dupes because duplicate_remover dict has moved 1 level down i.e. key will not be in there anymore\n",
    "                    type_to_check = d_no_dupes\n",
    "                    for key in key_loc[:len(key_loc)-1]:\n",
    "                        type_to_check = type_to_check[key]\n",
    "                    if len(key_loc) == 1 or type(type_to_check) !=dict:\n",
    "                        key_new = key_to_replace+'_'+str(key_loc[len(key_loc)-2])\n",
    "                        replacement_dict = d_no_dupes\n",
    "                        #You use d_no_dupes because duplicate_remover dict has moved 1 level down i.e. key will not be in there anymore\n",
    "                        if len(key_loc)>1:\n",
    "                            for key in key_loc[:len(key_loc)-1]:\n",
    "                                replacement_dict = replacement_dict[key]\n",
    "                        replacement_dict[key_new] = replacement_dict.pop(key_to_replace)\n",
    "                        duplicate_remover_dict.pop(key)\n",
    "                        no_dupes = 1\n",
    "                        all_keys_temp = {}\n",
    "                        break\n",
    "                else:\n",
    "                    all_keys_temp.update({key:value})\n",
    "        if no_dupes ==0:\n",
    "            duplicate_remover_dict = dict_temp\n",
    "            all_keys.update(all_keys_temp)\n",
    "    return d_no_dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data dictionary\n",
    "key_list = [\n",
    "    'id',\n",
    "    'name',\n",
    "    'firstname',\n",
    "    'lastname',\n",
    "    'headline',\n",
    "    'subdomain', \n",
    "#    'name', need to rename using retrieve key function\n",
    "    'shortcode',\n",
    "    'title',\n",
    "    'stage',\n",
    "    'disqualified',\n",
    "    'disqualification_reason',\n",
    "    'hired_at',\n",
    "    'sourced',\n",
    "    'profile_url',\n",
    "    'address',\n",
    "    'phone',\n",
    "    'email',\n",
    "    'domain',\n",
    "    'created_at',\n",
    "    'updated_at',\n",
    "]\n",
    "# Create DataFrame column labels\n",
    "df_dict = {}\n",
    "for key in key_list:\n",
    "    df_dict[key]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest entry:\n",
    "\n",
    "section = 'candidates?'\n",
    "limit='100'\n",
    "\n",
    "d = datetime.datetime.today().isoformat()\n",
    "r_last_cand = r = requests.get(url+section+'limit='+limit+'&created_after='+d+'.json', headers=headers)\n",
    "while len(r_last_cand.json()['candidates'])==0:\n",
    "    d = (datetime.datetime.today() - datetime.timedelta(days=1)).isoformat()\n",
    "    r_last_cand = requests.get('https://jdriven.workable.com/spi/v3/candidates?limit=100&created_after='+d+'.json', headers=headers)\n",
    "last_id = r_last_cand.json()['candidates'][-1]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build initial database\n",
    "\n",
    "# Get first page\n",
    "cand_id_list = []\n",
    "workable_start_date = '2010-01-01T10:10:10Z'\n",
    "r_cand = requests.get(url+'candidates?limit='+limit+'&created_after='+workable_start_date+'.json', headers=headers)\n",
    "for cand in r_cand.json()['candidates']:\n",
    "    cand_id_list.append(cand['id'])\n",
    "    for k in key_list:\n",
    "        loc = locate_element(cand,k)\n",
    "        v = cand\n",
    "        for i in loc:\n",
    "            v = v[i]\n",
    "        df_dict[k].append(v)\n",
    "since_id=r_cand.json()['paging']['next'].split(\"since_id=\",1)[1]\n",
    "\n",
    "# Get next pages\n",
    "try:\n",
    "    while last_id not in cand_id_list:\n",
    "        r_cand = requests.get('https://jdriven.workable.com/spi/v3/candidates?limit=100&since_id='+since_id+'.json', headers=headers)\n",
    "        for cand in r_cand.json()['candidates']:\n",
    "            cand_id_list.append(cand['id'])\n",
    "            for k in key_list:\n",
    "                loc = locate_element(cand,k)\n",
    "                v = cand\n",
    "                for i in loc:\n",
    "                    v = v[i]\n",
    "                df_dict[k].append(v)\n",
    "        since_id=r_cand.json()['paging']['next'].split(\"since_id=\",1)[1]\n",
    "except KeyError:\n",
    "    print('Last candidate entry retrieved')\n",
    "    last_id = cand_id_list[-1]\n",
    "    last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cand_db(last_id, cand_id_list):\n",
    "    '''\n",
    "    Update candidate database with any new candidates added after last candidate entry in DB\n",
    "    Key Arguments:\n",
    "    last_id -- id of last entry of the candidate database\n",
    "    '''\n",
    "    #Retrieve latest candidates\n",
    "    r_cand_upd = requests.get(url+'candidates?limit='+limit+'&since_id='+last_id+'.json', headers=headers)\n",
    "    if len(r_cand_upd.json()['candidates'])>1: # first item in the candidates list is already in the DB\n",
    "        for new_cand in r_cand_upd.json()['candidates'][1:]:\n",
    "            cand_id_list.append(new_cand['id'])\n",
    "        last_id=new_cand['id']\n",
    "        return cand_id_list\n",
    "    else:\n",
    "        print('Nothing to add')\n",
    "        print(cand_id_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_cand_db(last_id, cand_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_id_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame.from_dict(df_dict, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name']=='Paula L Amaral Santos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['firstname']=='Tim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_names = []\n",
    "for name in df['name']:\n",
    "    if df['name'].value_counts()[name]>2:\n",
    "        duplicate_names.append(name)\n",
    "duplicate_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name']=='Natasa Radenovic'].sort_values('created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r_cand.json()['candidates'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = change_name_duplicate_keys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locate_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "conn = mysql.connector.connect(user='root', password='maartens1991',host='localhost', database='recruitment_dashboard')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "cursor.execute('''CREATE TABLE candidates\n",
    "             (date text, trans text, symbol text, qty real, price real)''')\n",
    "\n",
    "# Insert a row of data\n",
    "cursor.execute(\"INSERT INTO candidates VALUES ('2006-01-05','BUY','RHAT',100,35.14)\")\n",
    "cursor.execute(\"INSERT INTO candidates (date,trans,symbol,qty,price) VALUES ('2007-01-05','SELL','RHAT',200,35.14)\")\n",
    "\n",
    "\n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "sql_select_query = '''SELECT column_name\n",
    "FROM information_schema.columns\n",
    "WHERE table_schema = 'recruitment_dashboard'\n",
    "AND table_name   = 'candidates'\n",
    "ORDER BY ORDINAL_POSITION\n",
    "'''\n",
    "    \n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_select_query)\n",
    "records = cursor.fetchall() \n",
    "columns = []\n",
    "for i in records:\n",
    "    columns.append(i[0])\n",
    "col_n = ','.join(columns)\n",
    "\n",
    "records_to_insert = [('2011-01-05','SELL','RHAT',700,40.14),('2010-01-05','BUY','RHAT',900,35.14),('2006-01-05','BUY','RHAT',800,35.14),]\n",
    "#params = ['%s' for item in records_to_insert[0]] # This needs to change as data input are not all stringers\n",
    "#params = ['%s','%s','%s','%d','%.2f']\n",
    "params = ['%s','%s','%s','%s','%s']\n",
    "var_string = ','.join(params)\n",
    "\n",
    "#sql_insert_query = \"\"\"INSERT INTO candidates (%s) VALUES ('2006-01-05','NOTHING','RHAT',400,35.14);\"\"\" %(col_n)\n",
    "sql_insert_query = \"\"\"INSERT INTO candidates (%s) VALUES (%s);\"\"\" %(col_n,var_string)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#cursor.execute(sql_insert_query)\n",
    "\n",
    "cursor.executemany(sql_insert_query, records_to_insert)\n",
    "\n",
    "print('here')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date,trans,symbol,qty,price'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSERT INTO candidates (date,trans,symbol,qty,price) VALUES (%s,%s,%s,%s,%s);'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_insert_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_to_insert = [('2006-01-05','BUY','RHAT',200,35.14),('2006-01-05','BUY','RHAT',300,35.14),('2006-01-05','BUY','RHAT',400,35.14)]\n",
    "params = ['%s' for item in records_to_insert[0]]\n",
    "var_string = ','.join(params)\n",
    "sql_insert_query = \"\"\" INSERT INTO candidates (%s) VALUES (%s);\"\"\" %(col_n,var_string)\n",
    "cursor = conn.cursor()\n",
    "cursor.executemany(sql_insert_query, records_to_insert)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [1,2,3,4,5]\n",
    "params = ['%s' for item in range(0,len(s))]\n",
    "var_string = ','.join(params)\n",
    "var_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['%s' for item in range(0,len(s))]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_query = \"\"\" INSERT INTO candidates (%s) VALUES (%s);\"\"\" %(col_n,var_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.tsv',mode = 'rt', encoding='utf-8') as csv_file, open('data_good.csv', mode='w') as data_good:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = '\\t', quotechar = '|')\n",
    "    records_to_insert = []\n",
    "    for row in csv_reader:\n",
    "        records_to_insert.append(tuple(row))\n",
    "records_to_insert_reduced = records_to_insert #[1:1000000]. len(records_to_insert) = 5590840\n",
    "params = ['%s' for item in records_to_insert[0]]\n",
    "var_string = ','.join(params)\n",
    "sql_insert_query = \"\"\" INSERT INTO movie_db3 (%s) VALUES (%s);\"\"\" %(col_n,var_string)\n",
    "#cursor = connection.cursor()\n",
    "#cursor.executemany(sql_insert_query, records_to_insert_reduced)\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'db204'\n",
    "'Niels Drost'\n",
    "'Niels'\n",
    "'Drost'\n",
    "None\n",
    "'jdriven'\n",
    "'A8C5321F60'\n",
    "'Big Data Scientist (BDR)'\n",
    "'1st Interview'\n",
    "True # Boolean\n",
    "None\n",
    "None\n",
    "True # Boolean\n",
    "'https://jdriven.workable.com/backend/jobs/3292...'\n",
    "None\n",
    "'+31 6 1543 4021'\n",
    "'niels.drost@gmail.com'\n",
    "None\n",
    "2016-09-05T10:05:28Z\n",
    "2019-02-01T14:56:34Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(user='root', password='maartens1991',host='localhost', database='recruitment_dashboard')\n",
    "    create_table_q = '''\n",
    "    CREATE TABLE candidates (\n",
    "    tconst varchar,\n",
    "    titleType varchar,\n",
    "    primaryTitle varchar,\n",
    "    originalTitle varchar,\n",
    "    isAdult varchar,\n",
    "    startYear varchar,\n",
    "    endYear varchar,\n",
    "    runtimeMinutes varchar,\n",
    "    genres varchar,\n",
    "    primary key (tconst)\n",
    "    );'''\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(create_table_q)\n",
    "    connection.commit()\n",
    "    \n",
    "    sql_select_query = '''SELECT column_name\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'recruitment_dashboard'\n",
    "    AND table_name   = 'candidates'\n",
    "    '''\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(sql_select_query)\n",
    "    records = cursor.fetchall()\n",
    "    columns = []\n",
    "    for i in records:\n",
    "        columns.append(i[0])\n",
    "    col_n = ','.join(columns)\n",
    "    \n",
    "except (Exception, psycopg2.Error) as error :\n",
    "    print (\"Error while connecting to PostgreSQL\", error)\n",
    "finally:\n",
    "    #Closing database connection.\n",
    "    if(connection):\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
